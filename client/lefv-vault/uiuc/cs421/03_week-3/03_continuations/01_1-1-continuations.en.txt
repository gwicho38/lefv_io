Hello everyone. Welcome to CS 421. Today, we're going to talk about continuation passing style. Continuations are a functional representation of what comes next in a computer program or computation. We can pass these continuations into functions just like any other high-order function, and can use them to do some really cool things. Here are our objectives for today. After you've walked through the content of this video, you'll be able to explain what continuation passing style is, and give some examples of programming techniques that CPS enables, write a recursive function using CPS. This'll be a warm-up for the following video, which will show you how to take an existing function and transform it into CPS. Here's some example code to consider. I've written three simple functions, inc, double, and half, that do the obvious things. Next, I compose them together as inc, double, half 10, and save the output in the variable result. Now, think about what is happening when we run this. Half will receive the value 10, process it, and then return it back. The function double will continue the computation by consuming half's output, processing it, and then returning it back. Finally, inc will continue the computation by consuming doubles output, processing it, and returning it back to be stored in the variable result. I'm sure you noticed that I talked about the function continuing the computation. We can make this idea very explicit. Imagine that we take an expression and punch out a sub-expression. In this case, let's punch half 10 out of its containing expression. That leaves an expression with a hole in it, which we can represent using these strange looking brackets. As an aside, these brackets are called semantic brackets. We make them by doubling up square brackets, and we use them frequently when talking about transformations that work on code. Anyway, we can call this expression with a hole in it, a context. After half 10 runs, its result is going to be placed into the context. If we turn in this context into a function, we can call it a continuation. Let's see how to do that now. Since a hole is just a spot where we can put a value later, we can represent that easily by wrapping it in a lambda, and letting the perimeter of the lambda represent the whole. In this case, let the continuation be lambda v arrow inc double v. For some reason, it's common to name the continuations argument v, Result began with the letter v, that would have worked for me but, oh well. Now the next thing we're going to do is augment half. You will take a second parameter which we call its continuation. By convention, the continuation argument is usually given a name beginning with the letter k. At least the word continuation starts with a k sound. When half is done, it's going to pass its result to the continuation argument. This has a very interesting effect. When we use continuation passing style, we can imagine that the half function never returns. Remember in the higher-order function lecture when we talked about using map to reduce the amount of code we needed to write, we could simply pass an operation into map, and it would recurse the list for us. A similar thing is happening here, but this time we are parameterizing how a function returns its value to the rest of the program. Now, Haskell doesn't have this, but many languages have an explicit return keyword that functions used to exit. You can imagine what we're doing here is parameterizing the return keyword. Now to summarize, we have seen two kinds of recursion so far. There is direct style, which is what most people would think of as normal recursion. There's also tail-recursion or accumulator recursion, whenever recursive calls happen in a function's tail position. Now we're going to go a step further. We're going to assume that when a function passes its result to a continuation, that the call to the continuation never returns. Once the call happens in tail position, it is likely that the bit about not returning is actually true, the compiler is going to optimize the underlying machine code to remove the intermediate stack frames. Now, let's look at some examples. In this slide, I've converted the rest of the functions from our initial example to use CPS. Inc and double are modified similarly to have, the interesting thing as result. The continuation fed into half 10 stores the output in v1, and passes v1 into double. But now double wants a continuation. So, we give it one that stores doubles output into v2. Finally, we can pass v2 in the inc. Inc wants a continuation, but we're done. So, we pass an ID to make it return the result back to the main program. So notice, we often we'll have occasion to nest one continuation inside of another one. One interesting thing people have noticed about CPS is how similar it is to imperative style. If you write the functions as colon equals style assignments, you get something that looks like an imperative program, so you can see that here. Let's look at an instance where CPS actually gets us something. This function here computes the greatest common divisor of a and b. It's not particularly slow, but it does have to do a bit of modular arithmetic. Now, imagine that we want to take the GCD of an entire list of numbers. We can call this function gcdstar, and its sources on the next slide. This is just a simple folding recursion. The function will traverse self down the list until it hits the empty list, and then compute the GCD of everything as it returns. Now, imagine that there's a one near the beginning of the sequence, what would happen? The GCD of one and anything is one, so all the GCD operations that happen on the rest of the list would be wasted. The same thing happens if we wanted to take the product of all the elements of a list, and somehow there was zero in that list, lot of multiplications would have occurred uselessly. There are several things we could do about this, like checking the list first to see if there's a one in it. But this is a lecture about continuations, so let's see how we can use continuations to fix this. I'm going to talk about this function, but you might want to pause the video and take a look at it first. All right. So, there are a few things to notice. First is that we have an auxiliary function aux, which uses its own continuation named newk. We initialize newk by calling aux with k. This has an interesting effect. Whenever aux is running, it has two separate continuations in its scope, its own current continuation newk and the gcdstar wide continuation k, there's nothing stopping aux from calling either one of these. In the base case, aux calls newk with the base case value zero. The usual recursive case, aux creates a new continuation by wrapping a lambda around the current continuation. The parameter res will get the result from their crystal called the aux, and call GCD on that and x, and then feed that result into newk. This is just an accumulator recursion like you've seen before, but we're accumulating now as a function or a computation. So far, so good. The magic happens on line three when we find a one in the list. Instead of calling aux recursively or using newk, we call the top-level continuation k instead. This bypasses all the computations that were in newk, so no calls to GCD will happen at all in this scenario, and the auxiliary function will abort as soon as it finds a one in the list. We basically implemented exceptions using only pure functions. Now, in addition to stimulating exceptions, continuations can simulate multitasking. When they are used like that, they're called co-routintes. There are also more advanced versions of continuations called the limited continuations. They have names like shift and reset. Finally, some languages notably scheme, allow you to capture the continuation of a running program with a command called call/cc. I hope this gives you a good introduction to continuations, and in the next video, we'll show you how to transform a program written in direct style into continuation passing style.