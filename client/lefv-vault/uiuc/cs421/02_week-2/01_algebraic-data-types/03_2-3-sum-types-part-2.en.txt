I told you I was going to show you how to write Binary Search Tree Add using this. So, here is the code that you could use. Say in this data type tree that has a type parameter A, second have a node with an A in it, and then two subtrees of type A. Then, we can also have an empty. If you are doing this at home and I suggest you do, remember to put in a deriving show clause just so that you can print it out. So I'm going to write this function called Add BST and I'll put in the type signature. So, I wanted to work on integers and tree of integers, so the first parameter is going to be integer and can have a tree that contains integers and then it's going to output a tree of integers. So, the first case is on line four, if I add something to an empty tree then I'm going to return a node that has something in it and then two empty subtrees. Next, if I want to add something, some integer I to a tree with a node with a X in it in the left and right subtree. Well, I have to check now if I is less than X then what I want to do is create a new node with the X in it and then add I to the left subtree and then keep the right tree as is. Now, this is important to notice that as I said before, whenever you write down a constructor, you're allocating memory. So, note that we are not modifying the original tree, we are actually creating a new tree. So, if I is not less than equal X, we want to go down to the right side and that's what lines seven says. So, create a new node, we leave the left tree alone, so we're just going to store a pointer to the original left tree, and then we're going to add BST to the right, that's going to create a new subtree there. So, let's look at what this looks like in memory. So, let's suppose I have a tree T that has five, three, and a seven in it, and I say let U equal add T6. What's that going to do, it's going to start with the five, it's going to go to the seven, and it's going to build a six on to the left of a seven, right? But it's not descending the original tree and modifying, it's descending the tree and building a new one. So, U is actually going to look like this. So, when we go down to the left one, remember we created a node, we return the right subtree which is going to point to the three, and then the left side is going to be a new node, creating the seven which is going to have a node creating the six. I left off the empties just to save space. So, the big rule of thumb for functional data structures, remember everything is persistent, everything is immutable, is that if you want to make a change to something. Everything between the root and the point of change is rebuilt. Everything that's not on that path is recycled. So, look at this line here let V equal add U1. So, I'm going to add one to the U tree now and try to visualize what the memory diagram will look like. So, hit pause try to visualize what will happen then when you're ready hit unpause and I'll show you the result. All right ready, here we go. So, the five and the three had to be rebuilt and then the one is new construction but the seven subtree could be recycled and so you see that it's pointing into there. So, what you end up having happened with a lot of these data structures, is that there's an awful lot of interlinking going on and this is perfectly safe because you can count on the fact that none of this is going to get changed. So, it's perfectly safe to link it to a previous item. Now, one thing that you can do with something like this is if you've ever used a program that has multilevel undo. It's very very trivial to implement that with this kind of structure. You just go to U or go to T to get back what was previously there. If you're using what we call destructive update, which you would in a language like Java or C++, you have to store the information of how to undo the change which can be significantly more complex. So, while this may look like it's chewing memory or could be slow, in some cases actually faster than doing it the other way. Remember too, that the compiler is really smart and it's going to optimize a lot of stuff for us anyway, so that they can detect that we are going to reuse memory or rebuild memory that's never going to be used again sometimes it will update in place. So, I want to show you a couple of very important types. One of them is called Maybe. You're going to use this a lot. So, the idea is suppose you have a hash table and you look something up in the hash table, you asked for the key and then the key is not in there, so there's no corresponding value, what are you going do about it? There's a few things that languages do, some return null or nil which can be a problem because it may be that the value you want inserted is actually nil. So, there's one language Common Lisp has a lookup function, it returns actually a pair. It's complicated but the first thing is the value that it got back and if it is nil then there's a second thing that tells you, if the nil was really a value or if it was really not in there. Some languages will force you to actually do a check first to see if the values in there before you're allowed to look things up, some languages just throw an exception. Now, all these are kind of painful. Here's Haskell solution to the problem. We have this type called Maybe, which means that you might have it or you might not. So, there's two constructors, you have Just, you also have Nothing. So, here we have this get item, linear associative list. If we get item, a key and the list is empty that means the values out in there, so we return nothing. But if we get item, the key and the value and the key K is equal to K, then we return just be otherwise we do a recursion. So, here's a couple of examples. Get item three returns just turtle doves but get item five, sorry no diamond rings, no golden rings so you get nothing. Another one is called Either. Now, this one has two type parameters because Either can be either A or B and they're usually called left and right. The common use for this is that the left constructor is used to store an error message and they right constructor is used to store a result that succeeded. So, here it's the same sort of thing except instead of returning nothing, we say left and then key not found, so we're returning an error message. Then mnemonic of course is that the right contains the right thing, so both of these, the Maybe type and the Either type are very important. You'll see them a lot so I urge you to play with these examples so that you don't actually have to type in the data because these are built-in. Play with this so that you get a good sense for how they work. So, here's something for you to try. Here's the tree type again. Try writing add, find, lookup and delete. You will learn a lot about functional data structures by doing this.