[MUSIC] Hello and welcome back to Theory and
Practice of Data Cleaning. In the last few weeks,
we have looked at work flows and programs as a means to describe
data cleaning analysis pipelines. While work flows provide a high level
conceptual view of data flow and data dependencies, providence capture
runtime for example via tracing tools and logging tools provides users with
retrospective prominence information. This week we will look at an open
source tool called guess work flow. Whose aim it is to provide some of the
benefits of scientific work flow systems to users who work with
popular scripting languages. Such as R, Python, or Mathlab. A researcher who assembles
a data wrangling pipeline using any of these powerful and
convenient scripting languages can put simple yes workflow
annotations as comments in the script. The purpose of these annotations is
to let the script author declare and then share their workflow
model with others. Specifically data flow dependencies and
conceptual level steps and phases of the modelled workflow at
the heart or impossible to extract from the script alone can be simply
declared using yes workflow. The yes workflow tool can then be
used to extract those comments and pass them to a graph-rendering
tool called Graphviz. Having a visual model of a script-based
workflow already provides value for script authors. As it provides a high-level documentation of what might otherwise be a somewhat
cryptic and hard to understand script. But the Yes Workflow Toolkit offers
more than to provide a visual rendering of a modelled workflow for
one or more given scripts through related tools that we have
encountered before for example data. We can query prospective and
retrospective problems, graphs, and even hybrid combinations of these. Here we are entering again research land
that is we will be looking at tools and techniques that are currently
under development in the applied research community. Yes workflow is also the tool that you
should be using in the final project of this course. When you get a chance to link together
a number of data cleaning tools and techniques. Specifically, you will be using open
refine,, regular expressions, and possibly scripting languages such as
Python or R, for pattern based or syntactic data cleaning. After that ,you will then load
the clean data into a SQL like database to further inspect and explore it focusing in particular on
logic based integrity constraints. Finally, you should be documenting
the overall work flow using a yes workflow model. You will notice that you don't have
to embed yes workflow annotations. Inside of programs or scripts. In fact, your overall work flow might very
well have a combination of manual steps. For example, in open refine and
automatic steps. For example, using scripts or
database queries. Okay, let's get started with yes workflow. [MUSIC]