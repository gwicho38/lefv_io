[MUSIC] If you ask the question, what workflow
tools are most scientists using? Well, there are a couple workflow systems
out there and they are being used. But a much larger set of people are using
somewhat more down to Earth tools like Python, R, and MATLAB. And there are various reasons for that. First of all, that's much more
material out to learn these things. And there's a general purpose,
when you learn how to use R in Python, you can use it for lots of other things. And also there's a sort
of sense of empowerment. If you know how to do stuff,
it doesn't feel like you have to learn this brand new system that
has its very own way of doing things. You can use something that
you already kind of know and make incremental progress. So there's many good reasons why Python,
R, and MATLAB and so on are very,
very well adapted and part tools. But on the other hand,
they're not workflow systems, so some of the benefits,
where is my workflow diagram? Where is my provenance support? You have to add these to it, okay? So, a few years ago,
we noticed that seeing how high the adoption is of systems like R and Python for putting workflows together. We sort of corrected our course
a little bit to say okay, it's great if you've workflow system
that works for you, it's wonderful. But what if you don't? So much logic customer base for our tools that if we look at people
who use R and Python and so on. So here's a project, a research project
that NSF, funded research project that kicking into gear now and quite active. It's called SKOPE, Synthesized Knowledge
of Past Environments. And what the scientists there do, you can think of them as
computational archaeologists. They try to understand what
happened about in the year 1300. For example, there were these migrations of Pueblo
Indians in the South West of the US. They kind of moved round and
certain villages were abandoned and it try to understand this. A part of the hypothesis there is that,
in those years, in certain years, climate has changed. So that maybe they're crop refilling or they needed to trade more with
the other tribes that were nearby. So, that's the whole
archaeological side of things, but then there's also sort of
climate science side of things. And so what is important for
them is to try to retrodict, so that was called paleoclimate, understand what
the climate will say a thousand years ago. And how can they do this? Well, we have climate models. We have computational science models
that can simulate basically climate. But we need to also feed it
with some observational data. So we have only indirect observational
data from those days, right? Nobody was in the 1300s. People were not keeping strict
records of precipitation and temperature, imagine 1300s, not likely. In the southwest of the US,
not likely either, but we have tree-ring data from those years. So there are trees and tree ring databases
that give us some proxy data that tell us, okay, this was a warm year probably. This was a wet year because
depending on how warm and wet a year is,
a tree will grow more or less. So from the tree rings, you can do this. And this is a really active area of signs. And so these fellows take these tree
ring databases, put them together, integrate them, and
feed some climate models. And they can create these wonderful
plots that basically make estimates what based on the data how dry or wet or
warm or cold a particular region was. What do they do for that? They don't use a workflow system,
they use R, okay. So use the R script and now I want to
look at, well, is there climate science? Is there computational
archaeology that they're doing? Can I reproduce this finding? Can I explain it? What data sets are they using? What parameters are they using and so on? Okay, so this is the kind of
an excellent use case for us to try out some technologies there. So here's the particular article or one of several articles that
these folks have written. And again, not surprisingly, they have
these charts and plots and so on. And there are papers. And they're good data scientists
in that they share their code too. So you can download the code and
you can redo this. But we feel that sometimes you
need to know a little bit more than just sharing the code. Sharing the workflow itself and then asking questions about
what depends on what and so on. And so we've begun to use or develop
a tool that supports scientists who write scripts and give them some
of the benefits of workflows. So if you recall, I had summarize of the
point of workflows was to help automation, scaling, abstraction, and provenance. Yeah, this is a course view of the world. How do you call these things? The customer rating of scripts. Well, scripts are good at automating
things that is what scripts are for, scaling, you have some extra work. You have to use your own libraries and
write your own code. Abstraction, not so much. All right, I mean script does what
it does quite well typically. But looking at that code, it's not so
clear, especially if it's not the author. Even as an author you might find
this difficult after months. But as somebody who's not the author, you might not really know is
the script the right for me? And then again provenance
support is also limited. So the idea was, can we create a workflow diagram from a script which
would help with the abstraction? Because now we have a high-level view,
a conceptual view of the script. That shows us what are the data elements,
what are the steps and how do they connect up. And then maybe we can also
have some provenance support, maybe we can look at the workflow
graph itself, ask questions of it. What depends on what. And then we can also compare it with the
retrospective provenance we've collected. And all of that is now available for
scripts, if only we knew how. So we've begun to develop a tool,
it's called YesWorkflow. It started as a grassroots effort from,
we had this idea using different projects where we
kind of tried to provide these projects with some support for provenance
and workflow support for scripts. And so
let me show you briefly how that goes and then I'll go into more detail next time. Actually, let me fast
forward here a little bit. So this is our goal here. So we have a script. We throw in annotations into the script,
so it is not really possible to automatically
extract a workflow diagram from a script. At least not the conceptual
workflow diagram. There's just certain things that
[INAUDIBLE] mismatch of what's being described by the code and
the way you think about the code. You can always say well,
why can't I automatic? Just automatically analyze the script. First of all,
it's very hard to automatically analyze any programming language. That's the radical reasons we
know from computer science. Non-trivial properties like termination
for example, are generally undesirable. So there's very hard theoretical
barrier to what we can do with prosthetic analysis and
it's hard in general. But more importantly or
in this particular case, it's also again,
how you think about your script. That's just not in the script itself. Maybe you thought one thing and the script
does it in a certain, contrived way. But you want to communicate the simple
way, the way you've thought about it. And you don't want to talk about
variables and if then analysis and function calls and
low-level data structures. You want to talk about the big picture, so somebody can appreciate what
it is that you're doing. And decide maybe they
want to reuse the method or do something similar or different. And that's what we do with
this YesWorkflow tools. The scientist puts these annotations, we call them YesWorkFlow
annotations in this script. And then the tool creates a graph for
me and then we can query this graph and continue to work with it. So here is a simple diagram that was
created by this clever agent here, Kyle Bocinsky. Who is this computational archaeologist
and he makes little advertisement there. He says, took me about 20 minutes to
comment or model my script as a work for one of several of many scripts. And so once you got the hang of it,
it's rather easy. [MUSIC]