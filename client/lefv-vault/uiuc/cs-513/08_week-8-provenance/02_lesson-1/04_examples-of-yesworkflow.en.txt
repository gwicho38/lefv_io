[MUSIC] [SOUND] Now let me show you a couple
of examples just to show that this is practically feasible. So here is a workflow
diagram that was created for a script from a collaboration
called MsTMIP. So that's Multiscale Synthesis and
Terrestrial Model Intercomparison Project. So this a project where climate
scientists compare their simulation models against one another, to kind of
comparing it against the benchmark and sort of ranking the models,
comparing the models. And in this context,
there are various scripts being used. And again if you want to explain
what the script is doing, then looking at the diagram like that
gives you quickly a high level overview. And also you see data dependencies
quite nicely that way. Again this comes from the DataONE project,
he has a very different use case. Here is bioinformatics
use case once again. In this case, the scientist is
interested really in the step. So it emphasizes the green box is here,
the computational steps and the data is sort of somewhat demoted
to just a label on the edge. So some people prefer this kind of diagram to quickly give a high
level overview what's going on. So in this case, you see there's
four green boxes, four steps. One is called normalize, stands for the normalization of data
across microarray datasets. So if you're in that domain,
this means something to you? Then you have maybe a selection
of differentially expressed genes between conditions. Again as a bioinformatician,
it's clear what's going on there. And then maybe you have determination
of gene ontology statistics for the result of data set. So GO stands for the gene ontology. And then maybe you create a Heatmap at
the end that is basically the final product of the data analysis. So it's rather easy to create such a
diagram and you can put it on your paper. But as we shall see it's not
just something you look at, it's going to be an artifact itself. A knowledge artifact that you can then
further use to ask questions about. So to illustrate a YesWorkflow a little
bit more, I'm going to use this example, which comes from something
that's implemented in Python. It simulates a physical workflow, a data collection workflow in the context
of something called X-ray diffraction. And as we shall see, this is a somewhat more complex script
that if you model it as a workflow, you can get additional understanding
of what's going on in the script. So imagine you have created and I'm
going to show this in a separate demo of this, how to create the workflow
using the tools, workflow diagrams. But once you have that,
you can query the prospective problems, you can query this workflow diagram or you
can even connect it to retrospective font. I want to show you this briefly,
how that works. So we call this approach
YesWorkflow recon or YW-RECON for reconstructing retrospective provenance
and linking it to prospective provenance. And sometimes we can get this almost for
free. So although we're not
using a workflow system, we can often harvest some
provenance information just by declaring certain connections between the
data files that the script uses on disk. And the conceptual model that
we've created that YesWorkflow diagram that you see on the left. So what you can do, and again I'm
going to show at a close up soon. Is we can declare for certain data
element, these are the yellow boxes. We can declare how they link to
artifacts that the script uses, namely files that the script uses on disk. And by making that link we're
going to we call this URI-templates. So it's basically a little bit
like a path expression that points into the file system or it could point to
URL, it could point to place on the web. It says, this data item that
I'm talking about here. Here's the URL or here's the URI and in this particular case the URI-template
describes the structure of that data. It's typically in some sort
of folder structure, and this is what you see on the right. So on the right you see,
basically a directory tree or folder tree that shows how this particular
script, the workflow organises the data. So at the top, you see there's a run
folder, maybe you have multiple runs of your workflow,
multiple runs of your experiments. And then there's subfolders
on the top near the top, you see something called raw. This is for raw images, and
then closer to the bottom, you see something that's called data. This is for the data produced
by the script, so this is for the transformed images. So often data is really organized
into these collections and you can map these collections
into folders on disk. And now wouldn't it be interesting
if I could look at these files that are generated, consumed and
produced by this script. And I could link that to my
conceptual model that I've created. This is something we
can do with this tool. So again, in the first step you
would have annotated your script to create a YesWorkflow model, so
we've talked about this already. So we're kind of past that step, but
we assume you have already done this. You mark the beginning and end of a step,
and the input and output and then things are connected
up that way by the system. Now you run the script. Once you've run the script of course,
files are read and written. Now we're sort of in
the retrospective provenance land. Because now after the script run,
stuff has happened. And so we can look at the artifacts
that were left behind. And we try to now connect them to the
model that we've created ahead of time to the prospective model. [COUGH] And in order to do this, we kind of invoke a particular function
of the CS workflow tool called recon. And what the tool does then at this point,
it looks in the model, looks at the URI-templates and
finds the corresponding items on disk. And then sort of builds that bridge
between the retrospective and the prospective provenance. And then subsequently,
you can now query the combined model. And I'm going to show you with some
examples, what is meant with that, why that is a good idea and
how you can get some value out of this. So let's look at this data
collection workflow again. So on the left, you have the workflow
diagram and then on the right, you have the artifacts left behind
by the execution of the script. So again,
the first step was to create the model. The second step is to run the script and to look at then the metadata
that you see at the right. And what does this allow you to do? It allows you to ask questions about
the processing history and data lineage. So you would like to know
certain things about your data. Well, because you have created
this model and you have connected the model to the trace information,
to the retrospective problems information. In this case, it's really just
the files that are left behind on disk, not left behind but are left on disk,
but executing the script. You can now answer certain
questions that previously you would not be able to answer. Previously you would have
to browse those folders, navigate those folders and
try to make sense of it. But now it's rather explicit, so there are
queries that are now associated with your experiment, with your workflow or your
script, and these queries can be executed. So you can look at the queries and you can
look at the results of the queries, and then they tell you something
about the processing history. So for example, you might have this question, what samples
did this script run collect images from? So again for context here this is a
workflow model of a script that simulates the collection of data from
an X-ray defraction experiment. Where basically cassettes
are put into some sort of instrumental set up where images
are taken at high voltages. And then the X-ray crystallographers, what they're trying to do is they try to
infer something about the structure of the crystals in the molecular structure
based on the defraction images they see. So there's some rather famous defraction
images that you might know about. If you are a little bit
interested in biology, you might know something
about the history how the structure of DNA also called
the secret of life how that was uncovered. It involves certain gentlemen
by the name of Crick and Watson. And also female scientists
Rosalind Franklin, who actually took the pictures
that helped these two guys figure out how DNAs put together actually
as the double helix, okay? So that's actually an interesting
science story that you can read about. So we're talking about an instrument that
does extra diffractioning images to figure out structures of crystals, and
this is the workflow that goes with it. And so as part of this workflow,
images are being taken. So there's data about samples that
are put under the instrument. And then we have to decide based maybe
on some quality measures, should we take another picture, should we take
another image of this sample and so on. So in particular this question, what samples did the script
run collect images from? So what were the samples? We want to answer this question, and
because we've created this model. We can now look both in the diagram
on the left of the Workflow model, but then also connect it
to the data that's on disk. So we would see this understand that
there's a certain folder level, maybe two folders down or so,
that corresponds to the samples. We would know this from
the model on the left. So the model on the left tells us,
go here, look what folders are there, and those are your samples. So the connection is made by declaring inside of your model
a certain URI-template, and what you cannot see because it's
a little small thumbnail here. But it is basically like
a path expression, so it looks like a directory path a/b/c. And then you have this curly braces
in the path expression there that makes it really a template. And that says, okay, at this level I have
samples, yeah, so the sample identifier. So the folder name
corresponds to this artifact in the URI-template in
the YesWorkflow model. Let's say you want to know, okay, so
what were the energies that were used for a particular image collection
from this particular sample? So let's say, you have a particular
sample identified which you know is in a certain folder
in your directory tree. And the sample is maybe called DRT322, and now you want to know well what
were the energies used for that? Yeah, this information is somehow
embedded often in practice, in file names and folder names. It's maybe not always
the ideal way to do it, but it's actually very practical way for
the scientist to keep some sort of organization about the data
that often sits in files. Your more often than not data does not
live in a database as we wished it does. But for various reasons, including
flexibility, convenience and so on, sometimes scalability data just
sits in files, on the file system. But you need to put some organization
to it, so if you have some nice hierarchical organization and
you have a naming convention. But then you can use that information
quickly, get it back out, and answer those kinds of questions. So if we want to know what energies
were used for image collection, from this particular sample,
we can see this information. It is left behind so to say, by the script
in the form of folders names or parts of names of folders or files, okay? So in this particular case, the sample, we already know is somewhere in the
directory structure at a certain level. We look at the folder name and
that's DRT322, well that's the particular
sample data is below that. And then it has subfolders, which collect
image data at different energy level. So here we see, probably barely see
that there are two different subfolders. One called E 10,000 and
the other one E 11,000. And these are their voltage electron
volts at which the image was taken. So the image is taken at 10,000
volts would be in one subfolder, and the ones at 11,000
would be another subfolder. So by keeping things
nicely separate that way, you can just look at the folder structure
and again you know this information. And how did we make that connection? Well in the model, we explicitly modeled
the fact that samples are the certain folder level and then energies
are at the subfolder level of that. So think of this again as a path
expression that has folder names and subfolder names. And it's a URI-template,so there's
no hard wired name there, but we put sorts of a variable there. We'll say, okay,
her's parameter that you like or a variable that indicates whatever you
find at that level and the hierarchy. Those names think of them as sample IDs. And into the sub folder, think of
those names as encoding the electron, the energy level at which
the image was taken. And so it goes again, you can ask all
kinds of detailed questions there. For example, you might now want to trace
a particular data lineage of your script. So if you want to know, okay, where's
the raw image of the corrected image DRT322_11000 electron volt and
then frame number 30. Okay, so where is the raw image for that? So there is a step called transform
images near the bottom of this workflow, basically near the end of the script. Corrected image, corrected images pop out,
there is some sort of image transformation that happens, but you want to
see the original image for that. How would you know that? Well in this case, again the data
has been organized in a certain way. So the file name gives away
a lot of the metadata. And what the YesWorkflow tool does,
it allows you to say, what is the pattern by which you have encoded this
important metadata into the file name? So we can extract that and make it,
so give it back to you and now you can ask questions about it. We would know from the file name, these
three different pieces of information. The sample ID, the energy level, and in this case the frame number,
so this was frame number of 30. And now, because we have that model,
we can kind of point to another file that was used as the raw
image of this output result. So because we have the pieces of metadata, we can now look in another
folder somewhere else. And we find the same sample ID,
we find the same energy level, we find the same frame number. And the model tells us,
well that this raw image file, taken from that sample,
taken at this energy level. This frame number gave rise
to this transformed image that has undergone this
image transformation step. The fact that I can see this at
the retrospective provenance level, in this case at the level
of files on disc. Is really facilitated by having in
the model a corresponding relationship between the outputs of the transform
image step and the inputs of that step. I use a similar URI-template,
I've made this connection explicit. In my workflow diagram, I said okay,
here's a step that consumes this data. This is how this data is laid out. It's consumed by this step and
it gives rise to a new set of data in another subfolder structure,
and here is the correspondents. So I have the correspondence in the model. Because I have it in the model, I can now harvest it on this can see
the instances of that relationship. And therefore,
I can answer the questions that I have. And here's a final example, just briefly, what cassette-id had the sample leading
to this particular output product? And again, you see the connection is
sort of anticipated in the model. So you see it through these circled ovals, there's these expressions that
correspond to one another. And in this case, you can go all
the way back to the overall input. So cassette-id is a global input
to this overall workflow or to this overall script. So it's all nicely connected
up in the model, and therefore become queriable
in this provenance. So what I've shown so far is really two
kinds of provenance information together, kind of very loosely coupled. One is the YesWorkflow model,
the diagram that I've shown to you. You think of it as prospective provenance,
sometimes I call it workflow land. It's basically that general recipe and
then it has the retrospective provenance or what I like to call
it sometimes traceland. The things, the artifacts that really
well left behind, runtime observables, filenames and so on there on disk. So this connection here has
been made in a certain way. I like to think of it on the cheap,
because the script that we were executing here did not
have a specific provenance recorder. It's really just all in the model. The information's all in the model and in the artifacts left behind by the script
in the file names and folder names. No additional recording was done. Which is kind of neat, it says,
I can tell something about the history of the processing history
of my data artifacts. Simply by exploiting the structure
of these artifacts on disk and having some of the knowledge
encoded in my model. So that's nice that I can uncover or
recover or reconstruct some provenance just from files and
folders and the YesWorkflow model. [MUSIC]