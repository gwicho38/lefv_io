1
00:00:08,142 --> 00:00:13,210
Let's go back to some finer
points of the W3C Prov model.

2
00:00:13,210 --> 00:00:18,950
If you zoom in to the standard you will
then find that what we call entity,

3
00:00:18,950 --> 00:00:24,180
or in our case, data itself can
be made up of different things.

4
00:00:24,180 --> 00:00:25,390
This could be a collection, so

5
00:00:25,390 --> 00:00:30,380
that could be nested data, often data
is structured into nested collections.

6
00:00:31,590 --> 00:00:34,610
There's something called a bundle and
something called a plan.

7
00:00:34,610 --> 00:00:38,410
This is a part of
the standard that I somewhat

8
00:00:38,410 --> 00:00:40,060
think of it as slightly confusing.

9
00:00:40,060 --> 00:00:42,880
A plan is really more a work flow thing.

10
00:00:42,880 --> 00:00:45,270
But it is, in this case,
associated with an entity.

11
00:00:47,390 --> 00:00:51,940
There's some method to this scheme,
but to the beginner,

12
00:00:51,940 --> 00:00:53,480
this might look a little bit confusing.

13
00:00:53,480 --> 00:00:58,270
And there's also different
relationships between entities.

14
00:00:58,270 --> 00:01:01,720
So we've seen before, there is
the wasDerivedFrom relationship, but

15
00:01:01,720 --> 00:01:06,360
there's also now variations of
what's influenced by Was quote from,

16
00:01:06,360 --> 00:01:09,570
was a revision of, or had primary source.

17
00:01:09,570 --> 00:01:13,950
So there's a little vocabulary of
relationships when you say this data was

18
00:01:13,950 --> 00:01:17,040
derived from this other data it
could mean different things.

19
00:01:17,040 --> 00:01:19,800
So the standard has further
refinements of that.

20
00:01:19,800 --> 00:01:22,370
And then again agents who are agents.

21
00:01:22,370 --> 00:01:25,610
This could be a software agent as
I mentioned before, a process.

22
00:01:25,610 --> 00:01:27,700
Or it could be a person
maybe even an organization.

23
00:01:28,806 --> 00:01:32,390
And as standards go,
they have to also describe or

24
00:01:32,390 --> 00:01:37,310
prescribe what formats are used for
exchange of data in the standard, so

25
00:01:37,310 --> 00:01:41,930
you see some things like there's a date,
time.

26
00:01:41,930 --> 00:01:46,330
So this XML schema Standard for
that as well.

27
00:01:47,590 --> 00:01:48,520
Now let me zoom out.

28
00:01:48,520 --> 00:01:53,850
It is easy to get lost in these standards
with all their technical details.

29
00:01:53,850 --> 00:01:56,720
So I just want to put
things again back into

30
00:01:56,720 --> 00:01:59,890
context before I continue
here with the material.

31
00:01:59,890 --> 00:02:04,730
So I want to talk about
provenance as it shows up.

32
00:02:04,730 --> 00:02:09,340
In the most general setting,
namely in science.

33
00:02:09,340 --> 00:02:11,550
If you think about it, there's all these

34
00:02:12,640 --> 00:02:17,050
different notions of provenance
that really scientists care about.

35
00:02:17,050 --> 00:02:18,310
Cosmologists, for example,

36
00:02:18,310 --> 00:02:23,170
they ask very far-reaching questions,
literally far-reaching questions.

37
00:02:23,170 --> 00:02:27,380
They study the origin of the universe or
the cosmos.

38
00:02:27,380 --> 00:02:29,755
Biologists study the origin of life.

39
00:02:29,755 --> 00:02:35,020
Phylogeny's here ,you see
a little thumbnail there.

40
00:02:35,020 --> 00:02:38,490
If you're into genealogy, you want to
know where your family came from and

41
00:02:38,490 --> 00:02:41,340
what are the relationships,
again, you look back in history.

42
00:02:42,400 --> 00:02:45,120
There's also something
called an academic pedigree,

43
00:02:45,120 --> 00:02:46,840
which is sort of your academic ancestors.

44
00:02:46,840 --> 00:02:51,230
So if you have, for example,
a PhD in the mathematical sciences or

45
00:02:51,230 --> 00:02:55,900
computer science, there's a nice
online database where you can look up

46
00:02:55,900 --> 00:03:00,800
whether you through your advisor
are connected to some famous people.

47
00:03:00,800 --> 00:03:04,420
Maybe it makes you feel better about
your own academic history that way.

48
00:03:06,210 --> 00:03:09,000
Etymology of course is the study
of origin, where words come from.

49
00:03:10,260 --> 00:03:15,600
So earlier chain of custody
in the case of artifacts.

50
00:03:15,600 --> 00:03:18,530
And so
all of these different uses of provenance,

51
00:03:18,530 --> 00:03:21,810
they really use provenance to
understand The present, right?

52
00:03:21,810 --> 00:03:24,700
We use the past, we use the history
to understand the present better.

53
00:03:25,800 --> 00:03:30,790
And so this is also our connection to why
we study provenance in the context of

54
00:03:30,790 --> 00:03:35,840
data quality and science and
scientific reproducibility.

55
00:03:35,840 --> 00:03:38,890
The connection is if you
have a data artifact or

56
00:03:38,890 --> 00:03:42,470
rather a knowledge artifact in this case,
like this plot on the right hand side.

57
00:03:42,470 --> 00:03:45,210
You can say this clearly shows

58
00:03:45,210 --> 00:03:49,402
that temperatures were have
been rising recently, yeah?

59
00:03:49,402 --> 00:03:55,320
So there's on the y axis,
you see a temperature scale.

60
00:03:55,320 --> 00:03:58,040
It's in Centigrades, Celsius.

61
00:03:58,040 --> 00:04:01,980
And on the x axis you see years.

62
00:04:01,980 --> 00:04:04,370
And well, what do all these things mean?

63
00:04:04,370 --> 00:04:05,850
How did I arrive at this curve?

64
00:04:05,850 --> 00:04:08,060
Is this really something significant?

65
00:04:08,060 --> 00:04:10,980
How much can I trust this?

66
00:04:10,980 --> 00:04:12,830
This is why,
in particular in climate science but

67
00:04:12,830 --> 00:04:16,670
really in all sciences,
this topic of reproducibility is central.

68
00:04:16,670 --> 00:04:19,990
It's not science unless somebody
else can reproduce what I have.

69
00:04:19,990 --> 00:04:26,290
And in data science in particular Of
course, the point is if we output or

70
00:04:26,290 --> 00:04:30,490
put forward analysis results, we need to
document how we arrived at those results.

71
00:04:30,490 --> 00:04:33,980
We need to show the input data,
intermediate data.

72
00:04:33,980 --> 00:04:36,710
We need to show the quote,
we need to document all methods.

73
00:04:36,710 --> 00:04:38,520
And this is where provenance
comes into the picture.

74
00:04:39,810 --> 00:04:45,780
So for scientist to be transparent and
reproducible about what they're doing,

75
00:04:45,780 --> 00:04:48,400
we need to know these questions
that I have here on the slide.

76
00:04:48,400 --> 00:04:50,870
What input data went into the study?

77
00:04:50,870 --> 00:04:52,320
What methods were used?

78
00:04:52,320 --> 00:04:54,230
What were the particular
parameter settings?

79
00:04:55,540 --> 00:04:58,010
What were the calibrations used?

80
00:04:58,010 --> 00:05:00,470
So we want to know whether we can
trust the data and the methods.

81
00:05:01,620 --> 00:05:05,140
And again,
since Provenance is the lineage of data

82
00:05:05,140 --> 00:05:09,200
we want to track the origin where the data
came from and the processing history.

83
00:05:09,200 --> 00:05:10,810
What tools were used to analyze the data?

84
00:05:10,810 --> 00:05:14,870
And then there's also
other uses of provenance.

85
00:05:14,870 --> 00:05:16,460
The primary use of
provenance is really for

86
00:05:16,460 --> 00:05:21,170
transparency and its broader context for
reproducibility.

87
00:05:21,170 --> 00:05:23,580
But then also you can discover,
for example,

88
00:05:23,580 --> 00:05:25,890
data and methods used on that provenance.

89
00:05:25,890 --> 00:05:29,514
I mean, at some point, provenance becomes
data itself, and you can index it,

90
00:05:29,514 --> 00:05:31,692
you can search based on provenance,
and so on.

91
00:05:33,656 --> 00:05:40,280
So let me show you some more
examples Of that before we move on.

92
00:05:40,280 --> 00:05:45,870
So again this is climate change,
a hot topic these days.

93
00:05:45,870 --> 00:05:50,790
And there was an online
database developed,

94
00:05:50,790 --> 00:05:54,270
GCIS, Global Change Information System.

95
00:05:54,270 --> 00:05:58,110
And it has plots like the one here.

96
00:05:58,110 --> 00:05:59,960
And metadata that's indicated.

97
00:05:59,960 --> 00:06:01,440
So let me zoom into this a little bit.

98
00:06:01,440 --> 00:06:06,750
Here's an example from the Texas Summer
2011, a record heat and drought.

99
00:06:06,750 --> 00:06:09,590
And the data visualized

100
00:06:09,590 --> 00:06:14,800
in the upper right is described
through metadata that's on the left.

101
00:06:14,800 --> 00:06:16,020
For example, we have a bounding box.

102
00:06:16,020 --> 00:06:19,830
We see this dataset is about
this region of the US.

103
00:06:19,830 --> 00:06:22,050
So there's this bounding box,
the blue box that you see there.

104
00:06:22,050 --> 00:06:25,550
And then there's these relationships
that we just talked about,

105
00:06:25,550 --> 00:06:30,030
provenance that say well,
how was this dataset created?

106
00:06:30,030 --> 00:06:35,360
So this dataset was derived from
another dataset Using an activity,

107
00:06:35,360 --> 00:06:38,060
using a process, or using a script.

108
00:06:38,060 --> 00:06:42,480
So if you were to zoom in here,
you'd get these problems records as part

109
00:06:42,480 --> 00:06:46,710
of this online database or
information system.

110
00:06:46,710 --> 00:06:51,920
So you can look at this Provenance
information just on the screen as HTML.

111
00:06:51,920 --> 00:06:54,390
But there's also a sort of
a machine-readable format.

112
00:06:54,390 --> 00:06:56,440
So if you click on one
of these buttons below.

113
00:06:56,440 --> 00:07:01,592
You can get this same provenance
information in JSON, in XML, Turtle,

114
00:07:01,592 --> 00:07:06,490
Triple syntax, all kinds of various
syntaxes that would allow you to

115
00:07:06,490 --> 00:07:10,992
write now queries or
other analysis on the provenance itself.

116
00:07:10,992 --> 00:07:14,260
So promised data becomes data itself,

117
00:07:14,260 --> 00:07:18,950
a promised information becomes data
itself that you can analyze in query.

118
00:07:18,950 --> 00:07:22,600
So this kind of state-of-the-art
here in provenance,

119
00:07:22,600 --> 00:07:27,880
when you do science, this report,
the Climate Change Impacts in the US,

120
00:07:29,180 --> 00:07:34,900
was a very large effort to document
how change in climate affects the US.

121
00:07:34,900 --> 00:07:39,927
And what was done, this information
system that's online here,

122
00:07:39,927 --> 00:07:43,711
is really to support
the findings of that report.

123
00:07:43,711 --> 00:07:48,218
And again, to support the findings
themselves is provenance information,

124
00:07:48,218 --> 00:07:50,350
to increase the trust it that.

125
00:07:50,350 --> 00:07:53,460
But creating provenance
information is still tedious and

126
00:07:55,620 --> 00:08:01,070
a large effort Which is why some projects,
for example DataOne mentioned here,

127
00:08:01,070 --> 00:08:08,450
creates products and tools that support
the creation of provenance in an easy way.

128
00:08:08,450 --> 00:08:12,520
As you conduct your scientific study,
wouldn't it be nice if the provenance

129
00:08:12,520 --> 00:08:16,510
information already was produced
as a side effect of your work.

130
00:08:16,510 --> 00:08:19,830
So it's not an afterthought
that later you have to kind of

131
00:08:19,830 --> 00:08:22,430
explain yourself after what you've done.

132
00:08:22,430 --> 00:08:26,090
But it would be nice that as you do your
science and in this case as you do your

133
00:08:26,090 --> 00:08:30,660
data science, or computational science,
if at that time province is captured.

134
00:08:30,660 --> 00:08:33,420
And then you can use it for
your own purposes as well.

135
00:08:33,420 --> 00:08:39,504
If you have Issues about data quality, you
can look at the Provenance information and

136
00:08:39,504 --> 00:08:44,337
find out what has happened and
maybe redo some of your experiments.

137
00:08:46,178 --> 00:08:50,795
All right, I don't want to say too
much about DataONE other than it's

138
00:08:50,795 --> 00:08:54,910
a federally funded large project,
so NSF funded.

139
00:08:54,910 --> 00:08:57,740
There's a website,
you can go there, DataONE.org, and

140
00:08:57,740 --> 00:09:01,350
in particular, there's a search
interface called search DataONE.org.

141
00:09:01,350 --> 00:09:06,510
And just very briefly, what it is, it's
really a federation of data repositories.

142
00:09:06,510 --> 00:09:09,080
It consists of so-called
coordinating nodes.

143
00:09:09,080 --> 00:09:14,250
You can think of them almost as the
brokers between other data repositories.

144
00:09:14,250 --> 00:09:17,820
The data repositories that
exist are called member nodes.

145
00:09:17,820 --> 00:09:21,500
So it's really a network of
existing data repositories.

146
00:09:21,500 --> 00:09:25,970
And then that's often associated
in investigative tool kit.

147
00:09:25,970 --> 00:09:27,970
So these are, in addition to the website,

148
00:09:27,970 --> 00:09:32,120
there are tools that allow you to work
with the data from those member nodes.

149
00:09:32,120 --> 00:09:35,460
Now I want to just finally make
that connection to provenance.

150
00:09:35,460 --> 00:09:39,070
So when you have identified the data
that you want to work with,

151
00:09:39,070 --> 00:09:42,718
some of the data, and hopefully
increasingly more of the data comes with

152
00:09:42,718 --> 00:09:44,920
provenance information attached.

153
00:09:44,920 --> 00:09:49,220
And on the website, you would see for
any dataset that you found using a search

154
00:09:49,220 --> 00:09:53,960
functionality, you might find this little,
the thing that looks like a pitch fork.

155
00:09:53,960 --> 00:09:57,680
Yeah, it is really an icon
meant to indicate that

156
00:09:57,680 --> 00:09:59,980
this data that has provenance with it.

157
00:09:59,980 --> 00:10:02,270
So this is saying,
here I have a data set but

158
00:10:02,270 --> 00:10:05,000
I can also tell you how
I got this data set.

159
00:10:05,000 --> 00:10:06,380
How was it computed?

160
00:10:06,380 --> 00:10:07,290
How was it derived?

161
00:10:08,730 --> 00:10:11,950
So this is a little bit highlighted there,
how that works and

162
00:10:11,950 --> 00:10:15,430
if you then unpack all of that you
might get the full on picture.

163
00:10:15,430 --> 00:10:19,500
You might see that maybe the plots
that you see in the lower right

164
00:10:19,500 --> 00:10:23,920
have been created using scripts and
other data set and

165
00:10:23,920 --> 00:10:30,490
that this difference of snapshots that are
stacked up there indicate how the output

166
00:10:30,490 --> 00:10:36,710
plots were created from input data sets
and scripts and how they connect together.

167
00:10:36,710 --> 00:10:40,470
And the thing we see in the middle is
a particular tool called Yes Book Flow

168
00:10:40,470 --> 00:10:42,320
that has created this diagram.

169
00:10:42,320 --> 00:10:47,560
This is as tool to present scientific
analysis that was conducted using a script

170
00:10:47,560 --> 00:10:52,030
saying Map Lab or
in this case as in R or in Python.

171
00:10:52,030 --> 00:10:55,100
If you have such a workflow
that's implemented as a script,

172
00:10:55,100 --> 00:10:56,840
you do want to also document.

173
00:10:56,840 --> 00:10:57,830
What other main steps?

174
00:10:57,830 --> 00:10:59,990
What is the the data flow in the script.

175
00:10:59,990 --> 00:11:03,750
What other main artifacts that
the script produces and consumes?

176
00:11:03,750 --> 00:11:06,631
It's important to document that and
this is a simple way to do so.

177
00:11:09,001 --> 00:11:18,947
[MUSIC]

178
00:11:18,947 --> 00:11:22,337
[SOUND]