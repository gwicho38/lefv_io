1
00:00:06,830 --> 00:00:10,065
Welcome to Theory and Practice of Data Cleaning.

2
00:00:10,065 --> 00:00:12,469
In this video, I will give an introduction to OpenRefine.

3
00:00:12,469 --> 00:00:17,149
We're gonna look at how to create a new project in OpenRefine.

4
00:00:17,149 --> 00:00:22,160
We'll look at basic normalization and the different facets that OpenRefine provides,

5
00:00:22,160 --> 00:00:23,420
for example, for text,

6
00:00:23,420 --> 00:00:25,629
timeline, and even scatterplot.

7
00:00:25,629 --> 00:00:30,589
Then we'll focus on the main task of what we want to use OpenRefine for,

8
00:00:30,589 --> 00:00:34,115
namely for clustering and editing cells.

9
00:00:34,115 --> 00:00:36,825
But we'll also look at the operation history,

10
00:00:36,825 --> 00:00:40,320
which introduces an important notion called provenance.

11
00:00:40,320 --> 00:00:43,359
And in separate videos, we'll then look at how to install

12
00:00:43,359 --> 00:00:46,390
OpenRefine and also look at advanced operations.

13
00:00:46,390 --> 00:00:47,494
All right, let's jump right in.

14
00:00:47,494 --> 00:00:50,979
OpenRefine is a power tool for data wrangling,

15
00:00:50,979 --> 00:00:54,670
specifically for getting an overview of the data.

16
00:00:54,670 --> 00:00:57,329
Sometimes this is also called data profiling.

17
00:00:57,329 --> 00:01:01,240
It's also used for detecting and cleaning certain kinds of data errors,

18
00:01:01,240 --> 00:01:04,459
which is the main function that we want to use it here.

19
00:01:04,459 --> 00:01:08,004
But we can also transform data and link data to other sources.

20
00:01:08,004 --> 00:01:10,329
OpenRefine used to be called Google Refine,

21
00:01:10,329 --> 00:01:14,754
so you might find also some related material online,

22
00:01:14,754 --> 00:01:18,879
references and so on using the previous name.

23
00:01:18,879 --> 00:01:21,780
We're gonna be using two different kinds of datasets.

24
00:01:21,780 --> 00:01:23,814
The first dataset is from the USDA,

25
00:01:23,814 --> 00:01:25,474
the U.S. Department of Agriculture,

26
00:01:25,474 --> 00:01:27,790
and this is Directory of Farmers Markets.

27
00:01:27,790 --> 00:01:31,390
This dataset is smaller and seems to be a bit more curated or

28
00:01:31,390 --> 00:01:35,734
cleaner data than the second dataset which we will also be using.

29
00:01:35,734 --> 00:01:39,609
That is datasets from the New York Public Library.

30
00:01:39,609 --> 00:01:42,204
It is a collection of historic restaurant menus,

31
00:01:42,204 --> 00:01:43,870
and it has been crowdsourced.

32
00:01:43,870 --> 00:01:46,090
That means a lot of people have contributed to

33
00:01:46,090 --> 00:01:49,109
this dataset and therefore this dataset is rather messy.

34
00:01:49,109 --> 00:01:51,504
OK, let's look at our first dataset.

35
00:01:51,504 --> 00:01:53,775
The USDA Farmers Markets data.

36
00:01:53,775 --> 00:02:01,469
So the USDA Farmers Market data can be accessed directly from the website from the USDA.

37
00:02:01,469 --> 00:02:05,959
And in fact, you can use the data on the website itself.

38
00:02:05,959 --> 00:02:09,914
But what about if you would like to work with the data directly, that is,

39
00:02:09,914 --> 00:02:14,565
perform some analysis on the data that is not supported by the simple web UI?

40
00:02:14,565 --> 00:02:18,415
In this case, you can go to the site and download the data itself.

41
00:02:18,415 --> 00:02:23,169
So, you can find a button near the lower left and say Export to Excel,

42
00:02:23,169 --> 00:02:25,455
which will really download the dataset.

43
00:02:25,455 --> 00:02:26,783
Once you've download the data set,

44
00:02:26,783 --> 00:02:29,014
you can then import it to OpenRefine.

45
00:02:29,014 --> 00:02:32,169
So we assume you have already installed OpenRefine at this point.

46
00:02:32,169 --> 00:02:36,909
And then we will go to the corresponding link,

47
00:02:36,909 --> 00:02:41,995
say Create Project, and then choose files to upload into OpenRefine.

48
00:02:41,995 --> 00:02:46,199
When you import data, you are provided a number of options.

49
00:02:46,199 --> 00:02:51,925
For example, you can import comma-separated values files or tab-separated values files,

50
00:02:51,925 --> 00:02:54,525
but also other kinds of data can be imported.

51
00:02:54,525 --> 00:02:56,319
Most of the time, the defaults that OpenRefine

52
00:02:56,319 --> 00:02:59,534
sets for you are already working very well,

53
00:02:59,534 --> 00:03:02,770
but you might want to check those different options to

54
00:03:02,770 --> 00:03:06,425
see which one is more suitable for your dataset.

55
00:03:06,425 --> 00:03:10,224
You also should give your project a suitable name,

56
00:03:10,224 --> 00:03:12,935
and then you can start importing the data.

57
00:03:12,935 --> 00:03:15,075
In the case of the Farmers Market dataset,

58
00:03:15,075 --> 00:03:20,575
we will have imported 8,664 rows fairly easily.

59
00:03:20,575 --> 00:03:23,849
And we are now ready to get a first overview of that data.

60
00:03:23,849 --> 00:03:28,949
So one of the first things you want to try out is the Text Facet.

61
00:03:28,949 --> 00:03:32,439
It is the workhorse for OpenRefine and

62
00:03:32,439 --> 00:03:36,335
gives you an overview of what values appear in a certain column.

63
00:03:36,335 --> 00:03:38,824
So you select the column, for example, here,

64
00:03:38,824 --> 00:03:42,969
MarketName, and then you select Text Facet.

65
00:03:42,969 --> 00:03:48,639
And you will then see that there are 8,095 choices.

66
00:03:48,639 --> 00:03:54,294
Meaning there's 8,000, about 8,000 different values in the MarketName column.

67
00:03:54,294 --> 00:03:58,125
And we have overall 8,664 rows,

68
00:03:58,125 --> 00:04:00,430
so some of them seem to be the same.

69
00:04:00,430 --> 00:04:05,156
And we see, for example, the most frequent value here is El Mercado Familiar,

70
00:04:05,156 --> 00:04:07,620
so there are 33 of those values.

71
00:04:07,620 --> 00:04:10,326
If you hit the Cluster button,

72
00:04:10,326 --> 00:04:14,229
OpenRefine will now try to cluster all of

73
00:04:14,229 --> 00:04:18,779
these different values into groups that are similar to one another.

74
00:04:18,779 --> 00:04:20,095
And once you've done that,

75
00:04:20,095 --> 00:04:22,149
you'll see you're presented with

76
00:04:22,149 --> 00:04:27,730
a rather informative screen that shows here all these different clusters available.

77
00:04:27,730 --> 00:04:30,069
And they give you a first idea of

78
00:04:30,069 --> 00:04:33,964
what kind of dirty data you might encounter in that particular color.

79
00:04:33,964 --> 00:04:35,680
So if you look, for example,

80
00:04:35,680 --> 00:04:37,464
at the cluster near the middle,

81
00:04:37,464 --> 00:04:43,314
you'll see it has four different ways of spelling Irvington Farmers Market.

82
00:04:43,314 --> 00:04:46,089
Some of these values occur multiple times,

83
00:04:46,089 --> 00:04:52,720
and these are likely typos that were created at the time of data entry,

84
00:04:52,720 --> 00:04:57,959
and they're still in this dataset although it is fairly organized and curated.

85
00:04:57,959 --> 00:05:01,769
So we can now click the button and select Merge.

86
00:05:01,769 --> 00:05:05,529
And if you're brave, you can in fact merge all of the clusters if they

87
00:05:05,529 --> 00:05:09,515
look good to you after you've checked that all the clusters seem reasonable,

88
00:05:09,515 --> 00:05:12,519
and also the name on the right that's being

89
00:05:12,519 --> 00:05:16,444
suggested by OpenRefine is the one that you want to use as the canonical name.

90
00:05:16,444 --> 00:05:20,995
So if you hit Merge and Merge Selected and Re-Cluster,

91
00:05:20,995 --> 00:05:25,064
you will then be causing a mass edit of,

92
00:05:25,064 --> 00:05:27,040
in this case, over 600 cells.

93
00:05:27,040 --> 00:05:28,569
So with a single click of a button,

94
00:05:28,569 --> 00:05:33,110
you have normalized all these values in the MarketPlace column.

95
00:05:33,110 --> 00:05:36,879
You will also notice that you've reduced the number of different values in

96
00:05:36,879 --> 00:05:43,240
this MarketName column from 8,095 to now 7,846.

97
00:05:43,240 --> 00:05:44,865
So you have, in fact,

98
00:05:44,865 --> 00:05:48,370
these groups or clusters of values,

99
00:05:48,370 --> 00:05:54,550
they have been now unified and you have now larger counts here for the MarketName.

100
00:05:54,550 --> 00:05:56,550
In this particular case for this dataset,

101
00:05:56,550 --> 00:05:59,699
a single iteration through this clustering step and

102
00:05:59,699 --> 00:06:02,699
then merging will already get the job done.

103
00:06:02,699 --> 00:06:07,365
We're done with normalizing the MarketName column and no further clusters are found.

104
00:06:07,365 --> 00:06:10,555
In more messy datasets,

105
00:06:10,555 --> 00:06:14,410
you might find new clusters after an initial clustering step,

106
00:06:14,410 --> 00:06:17,329
and so we will have to iterate this process.

107
00:06:17,329 --> 00:06:21,449
Now, what if you wanna apply this operation again?

108
00:06:21,449 --> 00:06:24,524
Or, if you want to just see what has happened to your data?

109
00:06:24,524 --> 00:06:32,235
There is a very useful tab in OpenRefine called Extract Operation History.

110
00:06:32,235 --> 00:06:34,524
This provides a sort of provenance information.

111
00:06:34,524 --> 00:06:39,824
So you see on the left, you have done a mass edit of 659 cells,

112
00:06:39,824 --> 00:06:45,990
and you can select now to extract the particular operations that were done and then,

113
00:06:45,990 --> 00:06:48,047
apply them in a separate dataset,

114
00:06:48,047 --> 00:06:50,185
apply those to a separate dataset,

115
00:06:50,185 --> 00:06:53,459
or you can just use it for documentation

116
00:06:53,459 --> 00:06:56,160
to understand what it is that you've done to the data.

117
00:06:56,160 --> 00:06:57,704
So, let's take a look at

118
00:06:57,704 --> 00:07:02,069
other facets that allow us to get an overview or profile the data.

119
00:07:02,069 --> 00:07:05,694
Another powerful facet other than the Text Facet is the Timeline facet.

120
00:07:05,694 --> 00:07:08,910
The Timeline facet is being selected for columns,

121
00:07:08,910 --> 00:07:10,305
you selected for columns,

122
00:07:10,305 --> 00:07:13,865
that have data that looks like it's temporal data.

123
00:07:13,865 --> 00:07:17,759
So, for example, the updateTime is a column in this dataset,

124
00:07:17,759 --> 00:07:20,670
and you can try and apply the Timeline facet to it.

125
00:07:20,670 --> 00:07:22,139
However, when you do that you,

126
00:07:22,139 --> 00:07:24,209
will notice that there's a problem.

127
00:07:24,209 --> 00:07:29,545
OpenRefine has not detected any time values and instead has marked all the values,

128
00:07:29,545 --> 00:07:33,694
all 8,664, as non-temporal values.

129
00:07:33,694 --> 00:07:37,860
So this is happening because you forgot to cluster or not to cluster.

130
00:07:37,860 --> 00:07:40,649
So what you need to do first is you go back to

131
00:07:40,649 --> 00:07:45,884
the updateTime column and then you select Edit cells,

132
00:07:45,884 --> 00:07:49,500
Common transforms, and then you convert the column from

133
00:07:49,500 --> 00:07:53,634
text data from string data to the data type date.

134
00:07:53,634 --> 00:07:54,870
Once you've done that,

135
00:07:54,870 --> 00:08:00,555
OpenRefine indeed notices that there are 8,131 time values in this column,

136
00:08:00,555 --> 00:08:04,350
and there are only 533 values left that seem to

137
00:08:04,350 --> 00:08:08,100
be not convertible in an obvious manner to a date.

138
00:08:08,100 --> 00:08:11,774
So, overall, you have now converted the data type of

139
00:08:11,774 --> 00:08:15,839
more than 8,000 cells from string to time.

140
00:08:15,839 --> 00:08:19,464
And now you can go back and do the Time Facet.

141
00:08:19,464 --> 00:08:21,390
Once you've done the Time Facet,

142
00:08:21,390 --> 00:08:25,050
you now can look at different time slices

143
00:08:25,050 --> 00:08:29,870
and get an idea of what values are in your dataset.

144
00:08:29,870 --> 00:08:35,090
For example, if you take a time slice that covers 2010 and 2011,

145
00:08:35,090 --> 00:08:39,169
you will notice that there's a lot of data missing for those time slices.

146
00:08:39,169 --> 00:08:43,294
On the other hand, if you look at the time slice that includes 2012,

147
00:08:43,294 --> 00:08:47,085
you will now see that there's a lot more data available for those years.

148
00:08:47,085 --> 00:08:52,049
So we've seen how the Timeline facet is very useful to get an overview of the data.

149
00:08:52,049 --> 00:08:56,149
And now, we're gonna look at another facet called the Scatterplot Facet.

150
00:08:56,149 --> 00:09:00,740
In this case, we also need to first convert the string data to numeric data.

151
00:09:00,740 --> 00:09:03,980
So this has been done for the column x already,

152
00:09:03,980 --> 00:09:07,274
and now we're gonna do this for a second column called y.

153
00:09:07,274 --> 00:09:09,870
And we, again, select Edit cells,

154
00:09:09,870 --> 00:09:15,134
Common transforms, and then convert to number, this column y.

155
00:09:15,134 --> 00:09:16,894
And once we've done that,

156
00:09:16,894 --> 00:09:19,129
you will see that both columns,

157
00:09:19,129 --> 00:09:21,440
the x and the y column now have numeric data

158
00:09:21,440 --> 00:09:26,259
which is indicated by the color coding of the green values.

159
00:09:26,259 --> 00:09:30,830
This now has transformed over 8,000 values from string to number.

160
00:09:30,830 --> 00:09:33,709
So we're now ready to use the Scatterplot facet.

161
00:09:33,709 --> 00:09:38,059
If we do that, if we select Scatterplot facet,

162
00:09:38,059 --> 00:09:40,700
we see the facet on the left,

163
00:09:40,700 --> 00:09:44,120
and it shows us a rather interesting picture that

164
00:09:44,120 --> 00:09:47,629
seems to resemble the outline of the United States,

165
00:09:47,629 --> 00:09:51,289
the continental U.S., and indeed these seem to be

166
00:09:51,289 --> 00:09:55,252
the locations of all the farmers' markets contained in this dataset.

167
00:09:55,252 --> 00:09:57,350
We can also work with this dataset now,

168
00:09:57,350 --> 00:10:00,371
exporting it and importing it into other tools,

169
00:10:00,371 --> 00:10:02,330
so in this particular case, for example,

170
00:10:02,330 --> 00:10:07,009
we use Google Maps which allows us to easily import CSV files.

171
00:10:07,009 --> 00:10:09,559
And we see here the data that we

172
00:10:09,559 --> 00:10:13,250
just looked at in OpenRefine now imported into a Google map.

173
00:10:13,250 --> 00:10:18,509
And you will notice that these data points that were off the map,

174
00:10:18,509 --> 00:10:21,334
in fact, are apparently valid datasets.

175
00:10:21,334 --> 00:10:26,190
We see, for example, that Hawaii seems to have farmers' market, and so does Alaska.

176
00:10:26,190 --> 00:10:31,549
So, this creates some confidence in the data that we've seen here.

177
00:10:31,549 --> 00:10:35,149
But we also know that there are three rows that couldn't be shown on the map,

178
00:10:35,149 --> 00:10:38,940
so we will probably have to go back in an actual study and look at

179
00:10:38,940 --> 00:10:43,179
the OpenRefine data at these particular columns.

180
00:10:43,179 --> 00:10:44,325
All right.

181
00:10:44,325 --> 00:10:48,120
So now I'm gonna give a quick summary of what we have seen in this video.

182
00:10:48,120 --> 00:10:53,399
We created a new project with OpenRefine and then had some basic normalization tasks.

183
00:10:53,399 --> 00:10:56,894
We were also using facets for text, timeline, and scatterplot.

184
00:10:56,894 --> 00:11:00,475
And then focused really on the main cleaning operation,

185
00:11:00,475 --> 00:11:03,235
namely clustering and mass edits.

186
00:11:03,235 --> 00:11:05,914
We also had a quick look at the operation history,

187
00:11:05,914 --> 00:11:08,605
which give us a form of provenance of the data.

188
00:11:08,605 --> 00:11:10,804
In separate videos, we will then be looking at

189
00:11:10,804 --> 00:11:14,670
advanced operations and also how to install OpenRefine.