1
00:00:00,000 --> 00:00:07,791
[MUSIC]

2
00:00:07,791 --> 00:00:10,818
And this is an example DataONE 2016.

3
00:00:10,818 --> 00:00:14,154
We have also a newer version of this,
but this one I have run before, so,

4
00:00:14,154 --> 00:00:16,200
hopefully this will give us less problems.

5
00:00:16,200 --> 00:00:19,027
So, the idea of this comes
with DataONE project and

6
00:00:19,027 --> 00:00:22,330
we had a little prototype and
post up for together for that.

7
00:00:22,330 --> 00:00:23,380
So, what's the idea?

8
00:00:23,380 --> 00:00:26,540
We have a number of, well, if you can
go to the demo, first of all you can

9
00:00:26,540 --> 00:00:31,220
clone this repository, this might actually
be in some sense cloning this repository,

10
00:00:31,220 --> 00:00:35,590
and playing with this demonstration might
be a good way for you to learn about, yes,

11
00:00:35,590 --> 00:00:38,610
workflow and that you can use them for
your group project.

12
00:00:38,610 --> 00:00:41,850
So, here's the set of the text
that introduces the demo,

13
00:00:41,850 --> 00:00:46,180
then the demo folders have a structure
that explains what's going on, so

14
00:00:46,180 --> 00:00:48,930
we have an examples folder where
we have different examples.

15
00:00:48,930 --> 00:00:52,171
I'm going to pick one that I walked
through after the break, and

16
00:00:52,171 --> 00:00:56,241
there are queries, which are queries
against the prominence information.

17
00:00:56,241 --> 00:01:00,988
And then there are rules that implement
the auxiliary rules that defines certain

18
00:01:00,988 --> 00:01:03,510
views that are needed for those queries.

19
00:01:03,510 --> 00:01:05,320
So, here's an example.

20
00:01:05,320 --> 00:01:07,516
You can see which artifacts
are being created.

21
00:01:07,516 --> 00:01:11,030
You know it gets around this demos,
is quite a bit of software that's been

22
00:01:11,030 --> 00:01:13,610
installed, because it brings
together different technologies.

23
00:01:13,610 --> 00:01:17,690
What I don't know from the top of my head
is whether we have a docker container

24
00:01:17,690 --> 00:01:20,570
that will make it easier to get
everything installed together.

25
00:01:20,570 --> 00:01:22,060
I think, we do have that.

26
00:01:22,060 --> 00:01:23,040
And I should look into that.

27
00:01:23,040 --> 00:01:25,640
But I have sort of native
installation here on disk.

28
00:01:25,640 --> 00:01:27,920
So, let's look at an example
first on the website.

29
00:01:27,920 --> 00:01:30,390
Let's just browse through it and
then I'll show you after the break,

30
00:01:30,390 --> 00:01:31,710
I'll show you some kinds on.

31
00:01:31,710 --> 00:01:33,100
We go to the examples.

32
00:01:33,100 --> 00:01:36,455
Let's say, we want to look at
this example called C3 C4.

33
00:01:36,455 --> 00:01:39,880
This is sort of a symbol
workflow simple script.

34
00:01:39,880 --> 00:01:43,360
That relates to coupon three,
coupon four models.

35
00:01:43,360 --> 00:01:46,640
The script itself is in a sub
folder called scripts, and

36
00:01:46,640 --> 00:01:49,310
so, let's just look at the script for
a moment how it looks like.

37
00:01:49,310 --> 00:01:54,073
So, it has this annotations and
it begins in, in, in and out.

38
00:01:54,073 --> 00:01:57,707
So, here we describe the whole script
as a whole retrieved as a black box as

39
00:01:57,707 --> 00:02:00,066
a workflow that as certain inputs and
outputs.

40
00:02:00,066 --> 00:02:04,380
So, we say, there's something called
SYNMAP_land_cover_data, which is an input,

41
00:02:04,380 --> 00:02:06,732
there's also a mean
temperature data input, and

42
00:02:06,732 --> 00:02:09,140
there's also a mean
precipitation data input.

43
00:02:09,140 --> 00:02:11,530
And the outputs there's
three kinds of output,

44
00:02:11,530 --> 00:02:15,140
C3 fraction data, C4 fraction data and
cross-section data.

45
00:02:15,140 --> 00:02:18,090
So, it looks like there are three
inputs and three upwards.

46
00:02:18,090 --> 00:02:20,390
But how do the inputs
depend on the outputs?

47
00:02:20,390 --> 00:02:21,400
Or rather, the other way around?

48
00:02:21,400 --> 00:02:22,950
How do the outputs depend on the inputs?

49
00:02:22,950 --> 00:02:24,120
We don't quite know that.

50
00:02:24,120 --> 00:02:27,370
In particular, we also don't know
what are these individual data items?

51
00:02:27,370 --> 00:02:31,970
From the UI template here, we see that
in fact, there are these variables,

52
00:02:31,970 --> 00:02:33,400
these curly braces.

53
00:02:33,400 --> 00:02:36,020
In this URI template, so
this is called a URI template.

54
00:02:36,020 --> 00:02:38,398
It annotates this mean temperature.

55
00:02:38,398 --> 00:02:41,380
So, mean a temperature is
a conceptual thing, a data element,

56
00:02:41,380 --> 00:02:43,300
a node in our workflow graph in the end.

57
00:02:43,300 --> 00:02:45,950
It says, well,
its an input to this overall script.

58
00:02:45,950 --> 00:02:47,110
But where does the input reside?

59
00:02:47,110 --> 00:02:48,140
Where is it on this?

60
00:02:48,140 --> 00:02:48,980
Where do I put it?

61
00:02:48,980 --> 00:02:49,810
So, you just declare that.

62
00:02:49,810 --> 00:02:50,950
You say, well, it's a file.

63
00:02:50,950 --> 00:02:51,830
It's not an URL.

64
00:02:51,830 --> 00:02:53,660
It's not on a website, or service.

65
00:02:53,660 --> 00:02:54,670
It's just a local file.

66
00:02:54,670 --> 00:03:00,000
There is an inputs folder and in it, there
is another sub-folder with a strange name.

67
00:03:00,000 --> 00:03:01,320
And then in that,

68
00:03:01,320 --> 00:03:06,690
there are these nc files, Net cdf files,
those are sort of scientific.

69
00:03:06,690 --> 00:03:09,590
It's a scientific data format for
often numerical data.

70
00:03:09,590 --> 00:03:11,340
And then it has, in the file name,

71
00:03:11,340 --> 00:03:13,490
something called start year,
end year and month.

72
00:03:13,490 --> 00:03:17,670
So, if we look in that folder,
just based on this declaration,

73
00:03:17,670 --> 00:03:20,060
we can already get an idea
what we're talking about.

74
00:03:20,060 --> 00:03:22,290
So, we might actually into
that inputs folder and

75
00:03:22,290 --> 00:03:25,750
try to look at the file name there,
and then extract that metadata.

76
00:03:25,750 --> 00:03:27,070
And similarly for the outputs.

77
00:03:27,070 --> 00:03:29,563
And then there's script self of course,
and

78
00:03:29,563 --> 00:03:33,632
again there are further comments
embedded here and there, for example,

79
00:03:33,632 --> 00:03:38,910
here we have step called examine pixels
for grass, that's the annotated has.

80
00:03:38,910 --> 00:03:41,600
Given that name itself it is inputs and
outputs.

81
00:03:41,600 --> 00:03:43,570
And then here's the code,
whatever it's doing,

82
00:03:43,570 --> 00:03:47,710
and then there's another step actually
this one has not been annotated, so

83
00:03:47,710 --> 00:03:51,320
this is possibly part of the set,
or this is commended out, or

84
00:03:51,320 --> 00:03:53,550
excuse me, I think,
this is all commended out, yeah, okay.

85
00:03:53,550 --> 00:03:57,320
And on it goes, you see the script
goes on, and on, and on, and

86
00:03:57,320 --> 00:04:01,350
it's not obvious from the script
itself what's going on.

87
00:04:01,350 --> 00:04:06,340
However once you've run YesWorklow tool,
you can then go to the results folder, and

88
00:04:06,340 --> 00:04:09,940
you go see various products
have been created by the demo.

89
00:04:09,940 --> 00:04:14,470
So, for example, as a starter we can
look at the complete workflow graph.

90
00:04:14,470 --> 00:04:17,850
So, this is the graph that was
created based on your model, and now,

91
00:04:17,850 --> 00:04:19,450
you see already much
better what's going on.

92
00:04:19,450 --> 00:04:20,800
In this we see three inputs.

93
00:04:20,800 --> 00:04:22,860
Precipitation, air temperature,
and land cover map,

94
00:04:22,860 --> 00:04:24,070
and we see these are the outputs.

95
00:04:24,070 --> 00:04:27,410
And we also see how
the outputs were derived,

96
00:04:27,410 --> 00:04:28,850
what were the steps that were involved.

97
00:04:28,850 --> 00:04:32,010
For your group project,
if you have a data cleaning workflow,

98
00:04:32,010 --> 00:04:35,380
you can have a similar diagram where you
explain what happened to your data set,

99
00:04:35,380 --> 00:04:37,690
and then I will work on this column,
that column and so on.

100
00:04:37,690 --> 00:04:40,066
You don't have to have a script for
creating such a model.

101
00:04:40,066 --> 00:04:42,130
So, refined you don't have a script.

102
00:04:42,130 --> 00:04:43,660
You work interactively with it.

103
00:04:43,660 --> 00:04:45,880
But you have then the operation history,
and

104
00:04:45,880 --> 00:04:48,940
then you can take the operation history,
maybe you could annotate that.

105
00:04:48,940 --> 00:04:50,350
Or you do it in a separate file.

106
00:04:50,350 --> 00:04:52,400
Or you just take notes
as you work with it,

107
00:04:52,400 --> 00:04:55,650
and then those notes form the basis for
your workflow diagram.

108
00:04:55,650 --> 00:04:58,268
Or you can make a plan ahead of time,
use the tool to plan and

109
00:04:58,268 --> 00:04:59,562
then try to follow the plan.

110
00:04:59,562 --> 00:05:02,764
And then as you will probably find,
[SOUND], there were other things that you

111
00:05:02,764 --> 00:05:04,930
didn't plan for
where you had to change your plan.

112
00:05:04,930 --> 00:05:07,300
There's a good chance that
will happen in real life.

113
00:05:07,300 --> 00:05:10,960
Okay, so this is a workflow
diagram that you can get, and

114
00:05:10,960 --> 00:05:14,393
then you can have particular queries,
for example,

115
00:05:14,393 --> 00:05:18,763
if you want to know what is upstream
of one of these outputs C3, C4.

116
00:05:18,763 --> 00:05:21,426
These almost looks like
a copy of the original graph,

117
00:05:21,426 --> 00:05:23,272
this is everything upstream of C3.

118
00:05:23,272 --> 00:05:26,580
You'll see it looks It seems
to have the same steps.

119
00:05:26,580 --> 00:05:29,650
It's not a complete graph,
because C4 is missing here, and so,

120
00:05:29,650 --> 00:05:30,950
some of the outputs are missing.

121
00:05:30,950 --> 00:05:34,360
But this is the result of a graph query,
where we said, tell me everything

122
00:05:34,360 --> 00:05:37,400
that went into C3 fraction data,
or that might have gone into it.

123
00:05:37,400 --> 00:05:41,280
What does C3 fraction data depend on,
in terms of the graph?

124
00:05:41,280 --> 00:05:44,210
So, this looks similar,
only slightly different,

125
00:05:44,210 --> 00:05:47,260
but there's another one that
looks much more different.

126
00:05:47,260 --> 00:05:51,240
So, if we look at grass fraction data,
you see it's a much smaller graph and

127
00:05:51,240 --> 00:05:53,610
it depends only on one input of tree.

128
00:05:53,610 --> 00:05:54,130
Okay.

129
00:05:54,130 --> 00:05:58,012
And then finally if you combine
the prospective problems information

130
00:05:58,012 --> 00:06:02,552
that YesWorkflow graph, YesWorkflow model
you combine that with retrospective

131
00:06:02,552 --> 00:06:06,957
prominence the way it could have come from
the workflow in this case the way it was

132
00:06:06,957 --> 00:06:11,035
reconstructed from file names and
folder names, we then get something we

133
00:06:11,035 --> 00:06:15,390
call hybrid proponents, or reconstructing
proponents and this is here.

134
00:06:15,390 --> 00:06:18,080
So, now, you see actually more details, so

135
00:06:18,080 --> 00:06:22,830
you would still get the higher level
diagram overview of your workflow, but

136
00:06:22,830 --> 00:06:25,630
now filled in with the concrete
files that were used.

137
00:06:25,630 --> 00:06:29,256
What you thought were three
outputs depending on 3 inputs

138
00:06:29,256 --> 00:06:32,448
turn out to be 3 outputs
depending on 25 inputs.

139
00:06:32,448 --> 00:06:36,232
But these 25 inputs were organized
into basically three groups, so

140
00:06:36,232 --> 00:06:38,395
conceptually, that's sort of.

141
00:06:38,395 --> 00:06:43,210
3 inputs, but the mean precipitation
is actually a set of 12 files, one for

142
00:06:43,210 --> 00:06:45,800
each month, and similar for
mean air temperature.

143
00:06:45,800 --> 00:06:47,770
Again, these are 12 files,
1 for each month.

144
00:06:47,770 --> 00:06:49,180
How would you be able to pick that up?

145
00:06:49,180 --> 00:06:50,840
Because there was a URI template.

146
00:06:50,840 --> 00:06:55,030
So, if that URI template has been
sort of instantiated with the values,

147
00:06:55,030 --> 00:06:57,320
based on the file and folder names.

148
00:06:57,320 --> 00:07:01,580
And you see that for the land covered
map data, that input is not by month,

149
00:07:01,580 --> 00:07:02,740
there's just one of them.

150
00:07:02,740 --> 00:07:04,940
And you can now ask additional questions.

151
00:07:04,940 --> 00:07:05,510
So, for example,

152
00:07:05,510 --> 00:07:10,140
if you ask what are the inputs that C4,
or C3 fraction data depends on?

153
00:07:10,140 --> 00:07:12,310
Your answer would be here to 25 file.

154
00:07:12,310 --> 00:07:15,020
If you were to ask what does
grass fraction data depends on.

155
00:07:15,020 --> 00:07:17,290
Here is the 1 file not the 20 file.

156
00:07:17,290 --> 00:07:18,880
Because if you carefully look.

157
00:07:18,880 --> 00:07:19,950
There is no path.

158
00:07:19,950 --> 00:07:21,940
So, there is a path from here to here, but

159
00:07:21,940 --> 00:07:25,310
there is no path from here all
the way to the other inputs.

160
00:07:25,310 --> 00:07:27,770
You can't get there, that means,
it doesn't depend on them.

161
00:07:27,770 --> 00:07:29,170
So, these are the things
that we can learn.

162
00:07:29,170 --> 00:07:32,409
We'll have a short break and
then after the break,

163
00:07:32,409 --> 00:07:35,504
I'll show you the running
example of the table.

164
00:07:35,504 --> 00:07:39,644
So, I'm going to show you in a moment
basically the demo prototype, which I've

165
00:07:39,644 --> 00:07:44,162
built using, by basically cloning from the
GIT repository HH try the newer version,

166
00:07:44,162 --> 00:07:48,767
the IGCC 2017, and that's going to work as
well, it seems, so I'm going to use that.

167
00:07:48,767 --> 00:07:52,690
What you want to do is basically
go to that GitHub site.

168
00:07:52,690 --> 00:07:56,064
If you Google yesworkflow.org, and it has,

169
00:07:56,064 --> 00:08:00,920
or just it's .org it will, I think,
re route you to this GitHub.

170
00:08:00,920 --> 00:08:05,542
And then there you can identify
the work IDCC 2017 demo, and

171
00:08:05,542 --> 00:08:08,890
then you go here click on clone,
or download.

172
00:08:08,890 --> 00:08:14,429
And then you get a URL, you copy that URL,
and then if you have done this before.

173
00:08:14,429 --> 00:08:19,018
You know what to do?, which is keep clone,
and if you haven't done that and

174
00:08:19,018 --> 00:08:21,290
you've got to git how to do that.

175
00:08:21,290 --> 00:08:25,150
That will give you a copy
of the repository.

176
00:08:25,150 --> 00:08:27,150
That does not mean that the demo works,

177
00:08:27,150 --> 00:08:31,090
because you still have to install
certain software on which this depends.

178
00:08:31,090 --> 00:08:33,650
And hopefully this is
explained somewhere here.

179
00:08:33,650 --> 00:08:35,690
So, if you carefully walk through this,

180
00:08:35,690 --> 00:08:38,600
hopefully, you should be able to
install the requisite software.

181
00:08:38,600 --> 00:08:41,260
And if there's a problem, it doesn't work,
we'd like to know about it.

182
00:08:41,260 --> 00:08:44,820
Since this is sort of developed in my
group, so whatever inconsistencies, or

183
00:08:44,820 --> 00:08:49,390
flaws, or whatever you'd find, just
post it on the class form, make a note.

184
00:08:49,390 --> 00:08:52,980
There are not problems, or so,
if you don't play with this and

185
00:08:52,980 --> 00:08:54,640
let us know, then we can fix it.

186
00:08:54,640 --> 00:08:57,640
Okay.
So, let's go to the demo proper.

187
00:08:57,640 --> 00:09:03,000
I'll first go through the website very
briefly one more time and then show you,

188
00:09:03,000 --> 00:09:06,600
because in the shell, what you see in
the shell is actually not that much.

189
00:09:06,600 --> 00:09:08,670
Want to give you first a mental
model of what's happening.

190
00:09:08,670 --> 00:09:12,790
So, again, on that demo side we have
an explanation of the demo itself.

191
00:09:12,790 --> 00:09:16,530
Overall the purpose of the demo
is to show different use cases,

192
00:09:16,530 --> 00:09:19,180
different scripts that have been
mocked up with YesWorkflow.

193
00:09:19,180 --> 00:09:20,430
And using the YesWorkflow tool,

194
00:09:20,430 --> 00:09:24,060
you can then create the graph,
the graphical model of these workflows.

195
00:09:24,060 --> 00:09:28,530
But you can also it is the focus
run queries, ask questions

196
00:09:28,530 --> 00:09:33,430
about the proponents, and then you will
see the query answers in text form,

197
00:09:33,430 --> 00:09:35,020
or also again in graphical form.

198
00:09:35,020 --> 00:09:38,540
So, in particular we have the following
ingredients, prospective problems queries

199
00:09:38,540 --> 00:09:41,340
in the context of a single script,
most of these examples are for

200
00:09:41,340 --> 00:09:45,730
a single script retrospective provenance
queries from a single script run.

201
00:09:45,730 --> 00:09:49,320
We also then have hybrid provenance,
where we combine the prospective and

202
00:09:49,320 --> 00:09:50,870
the retrospective information together.

203
00:09:50,870 --> 00:09:52,250
It's a little bit like that YesWorkflow,

204
00:09:52,250 --> 00:09:55,080
no workflow bridge,
in that flavor, in that style.

205
00:09:55,080 --> 00:09:57,610
And there's also part,
we're not going to go into it here,

206
00:09:57,610 --> 00:09:59,650
but there's also a more experimental part,

207
00:09:59,650 --> 00:10:03,640
where we're looking at provenance from
multiple trips and multiple runs.

208
00:10:03,640 --> 00:10:08,180
Because that's, I think, worth mentioning
that in practice as a say, scientist, or

209
00:10:08,180 --> 00:10:10,730
data analyst working with data sets.

210
00:10:10,730 --> 00:10:13,990
You will also have lots of scripts and
then you use them together.

211
00:10:13,990 --> 00:10:15,820
Sometimes, these scripts
as of chained together,

212
00:10:15,820 --> 00:10:17,450
maybe you have a preprocessing script.

213
00:10:17,450 --> 00:10:20,842
You run that a couple of times and a
couple of data sets until you get what you

214
00:10:20,842 --> 00:10:24,539
like, then you switch maybe to another
set of scripts to the actual analytics.

215
00:10:24,539 --> 00:10:27,793
And when you're done with that, then
maybe you go to a third phase where you'd

216
00:10:27,793 --> 00:10:30,470
post processing, and
create a certain output product.

217
00:10:30,470 --> 00:10:33,860
So, if you want to document that larger
process, you know you need extra

218
00:10:33,860 --> 00:10:37,865
things beyond the single script
provenance that we're focusing on.

219
00:10:37,865 --> 00:10:41,025
And here just for convenience
on the website, we put together

220
00:10:41,025 --> 00:10:44,545
a couple of snapshots, so you can
preview a little bit what's out there.

221
00:10:44,545 --> 00:10:45,855
So, let's just have a look.

222
00:10:45,855 --> 00:10:49,385
This is an example of a prospective
graph that you've seen before.

223
00:10:49,385 --> 00:10:51,135
Here is a hybrid graph.

224
00:10:51,135 --> 00:10:54,599
Again, prospective graphs
of instantiated with a file

225
00:10:54,599 --> 00:10:57,114
level information from the actual run.

226
00:10:57,114 --> 00:11:07,114
[MUSIC]