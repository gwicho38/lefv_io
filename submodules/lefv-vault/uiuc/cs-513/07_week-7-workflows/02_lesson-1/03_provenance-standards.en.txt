There's this notion of prospective and retrospective provenance that I already mentioned. And that's when I connect them here using this Kepler system as an example. So the workflow itself, so here's a simpler workflow, it's just a linear pipeline. The workflow itself we can sometimes call, sometimes is called prospective provenance because it gives the recipe of how a certain data analysis or data curation pipeline is working. So these are the steps I'm gonna do to my data --prospective provenance. When you then run the workflow, or sometimes you have a script when you run the script, you then often capture retrospective onto the prominent information, log files traces. So, this is the terminology that we want to use. And to simplify it further, I sometimes like to speak of Workflow-land and Trace-land. Yeah? So Workflow-land is your specification level, your schema level. This is my general recipe. And then Trace-land or retrospective provenance, well, this is what actually happened. And then you can easily imagine that there should be some correspondence between those two things. For example, your recipe says this step comes before that step. And then, in the trace, it looks like it's the other way around. You should flag that, something's wrong. Either you lied about the recipe in the workflow or something else at runtime went wrong. So this is a good mechanism to really have those two levels play against each other a little bit. Little bit of redundancy in the system. Here's how I think about the model or how I put it together if you have a workflow system, and here's what actually happened, and now let's compare. All right! So this is a comment on provenance standards and tools. There's a standard that we're going to look briefly at called the W3C PROV standard, and it provides sort of a minimal model of how you would capture, or how you would describe rather, retrospective provenance. So the W3C folks like to just call it provenance. For them all, typically all provenance is retrospective, so they don't talk much â€“ the standard doesn't really talk about the workflow that creates the provenance. This is we think of actually a shortcoming, but everybody might have a different workflow system, workflow approach. So it's not surprising that they didn't take that sort of scope and they didn't include this in the scope. They wanted a minimal standard really. But provenance is currently very much en vogue. It's a hot research topic. It's a useful technology, but there's a problem also with creating provenance. Right now, it's still difficult to create provenance. And even if you create it, how do you use it? How do you squeeze value out of it? And so everybody likes to talk about it. Everybody likes to use somebody else's provenance, like somebody else's metadata, but nobody wants to create it in the first place. And one of the problems is creating it and managing it is still somewhat tedious. And again, if you don't derive direct value from it for yourself, you might feel like you can skip this step. You know, day is short, there are lots of things to do in my day. Should I write the next paper, make the next study? Or should I document my data more and provide more provenance so that maybe somebody else can benefit from it? You can easily see where that decision is going. So that's why I think, as a community, it's important those who develop provenance tools and techniques need to think hard how they can create tools and techniques that give you immediate benefit for the people who are supposed to create the provenance in the first place. So how can I get some value out of it when I create this provenance, record it, and so on? So this is something we're gonna look at a little bit as well. OK! I call this provenance for self. So provenance feels like metadata in general. Metadata feels like often it's for others. You should document your code, you should you know your columns and your database schema. Well it is also for yourself, but often it doesn't hurt you immediately, it hurts you, you know, six months in the future, two years in the future. Yeah! But if on the other hand you have nice tools that allow you to do something with your documentation while you're still working on it, it's a much better incentive to actually use it. And I think the same is true for provenance. OK! So here is a simple model that relates prospective and retrospective provenance that we've used in one of our publications. So I have a reference there. As a first approximation, if you think of a workflow graph as literally a data flow graph as a diagram where, for example, steps like, here, the step A and B are connected through data containers, so for example, your X and Y and Z. So data X goes into A, producing Y, Y goes into B, producing Z. Oh and by the way, B not only uses the Y but it also uses the original X. If this is your recipe, if this is your workflow, then you would expect that at the instance level, when you look at the actual records and the actual dataset's being processed, you would see something that looks like that too. So the dependency at runtime that are logged and traced should resemble the ones that you have defined ahead of time in your workflow. And so, mathematically, if you want to get all fancy about it, you can try and define a homomorphism, which is sort of a mathematical construct to say this structure looks like that structure. And so, if it doesn't, maybe that's an indication that something went wrong and you can use that to maybe report what might go wrong. All right! Now, I mentioned that the provenance standard that I haven't really yet talked about but I will called PROV W3C does not deal with this upper level, with the workflow level. They only deal with the retrospective provenance level. They have relationship where, here for example, I use my own terminology, this is not standard terminology. I say read and write because this says that this function call or active invocation A was reading the X and was writing the Y. At the workflow level, maybe I want to use a different terminology so as to not confuse the levels. Maybe I want to call this in and out. So the schema workflow level I call something goes in, something goes out. And then at the actual runtime level, I call it maybe read and write, for example. Well, W3C has its own terminology. For reading, they say used. So, A used X, sort of the provenance or the data dependency direction is sort of in the other direction. Yeah! So the step A used X, and then Y was generated by A. Okay! So instead of write, you say sort of I write this data or I have written this data you say, Y was generated by A. Okay! That's W3C terminology. But we felt that it was important to link the prospective provenance graph, that is the workflow graph, with a retrospective provenance graph as well. So we developed a new extension to the PROV model which we call the ProvONE. We call it ProvONE because we wanted to show the lineage to the PROV standard, for the W3C PROV standard, and to the project that sponsored this work, which is called DataONE. So PROV standard plus DataONE gives you ProvONE. Okay? And this is basically slightly hard to decipher a schema here, but the idea is that, in it, it contains Trace-land, a retrospective provenance, which conforms to the standard, which is the W3C PROV standard, but then there's a connection to a bunch of other relationships that we call Workflow-land or prospective provenance. And then also we have some little bit more information about the extra data structures being talked about. Okay? All right! So I'll go into these details in the next lecture. But for now, I just want to come back to this point of provenance for self. So, right now, what we see is there are these data products out there. For example, here this is a national climate assessment from a few years ago that was put together with a lot of effort by a lot of people, and they tried to do a good job with respect to sourcing their findings. So they try to put all the provenance information there, and they even created a whole online information system or online database, GCIS, the Global Change Information System. And in that Global Change Information System, here's a snapshot of it. When they had a finding like a graph, they had lots of metadata about it, they say okay, this graph talks about this region, maybe Texas, here and it is about maybe record heat and drought in Texas in summer 2011. And they wanted to document how they have created this particular plot here. And so, again, I'll have more details on that, but they might show that this particular dataset was derived from this other dataset or input using this particular script. So they were pulling together provenance records, documenting basically what was done. But this feels a little bit like pulling teeth, running after the scientists who've done these studies, e-mailing them, contacting them, or looking at their papers, trying to put everything together. It sort of feels a little bit like reverse engineering or screen scraping. There's some data out there and we're looking just in the wrong place because that's the only place we have. And one of the reasons that people don't create more provenance on the fly and share it that, well, there's a lot of reasons. There's barely a standard out there when we haven't standard out there. But in terms of tool support, it's very much missing. And then also, even if you work in this area and you want to source and document what you're doing and provide this provenance information, it still feels like it benefits others. This is why I have here this fellow sitting here somewhat frustrated, saying "well, where's my value that I get of creating provenance?" So we want to prime the pump and create more provenance information by letting scientists themselves benefit from the provenance they create. So, currently, while we have tools for capturing provenance and we can even share and link the provenance, but the individual scientists who supposed to to create it for their own data they work, they don't have much tools there. So that's the idea of some of the research that's being done is how can we create provenance that's valuable. So they can use it in their own studies while they do the work. Maybe if I have some powerful provenance queries, maybe I can improve the quality of my findings. Maybe I detect the mistake before somebody else does. A year after I published my study, a mistake is found and, you know, maybe I could have caught this myself if I had better provenance support, for example. Or maybe just my studies, I can compile it faster if I have tools that allow me to more systematically steer my experiments.