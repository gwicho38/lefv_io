1
00:00:07,259 --> 00:00:12,380
There's this notion of prospective and retrospective provenance that I already mentioned.

2
00:00:12,380 --> 00:00:16,510
And that's when I connect them here using this Kepler system as an example.

3
00:00:16,510 --> 00:00:17,960
So the workflow itself,

4
00:00:17,960 --> 00:00:20,589
so here's a simpler workflow, it's just a linear pipeline.

5
00:00:20,589 --> 00:00:22,913
The workflow itself we can sometimes call,

6
00:00:22,913 --> 00:00:28,780
sometimes is called prospective provenance because it gives the recipe of how a

7
00:00:28,780 --> 00:00:34,719
certain data analysis or data curation pipeline is working.

8
00:00:34,719 --> 00:00:39,223
So these are the steps I'm gonna do to my data --prospective provenance.

9
00:00:39,223 --> 00:00:41,164
When you then run the workflow,

10
00:00:41,164 --> 00:00:43,355
or sometimes you have a script when you run the script,

11
00:00:43,355 --> 00:00:50,505
you then often capture retrospective onto the prominent information, log files traces.

12
00:00:50,505 --> 00:00:54,109
So, this is the terminology that we want to use.

13
00:00:54,109 --> 00:00:56,996
And to simplify it further,

14
00:00:56,996 --> 00:01:01,085
I sometimes like to speak of Workflow-land and Trace-land.

15
00:01:01,085 --> 00:01:05,629
Yeah? So Workflow-land is your specification level, your schema level.

16
00:01:05,629 --> 00:01:07,665
This is my general recipe.

17
00:01:07,665 --> 00:01:10,689
And then Trace-land or retrospective provenance,

18
00:01:10,689 --> 00:01:12,689
well, this is what actually happened.

19
00:01:12,689 --> 00:01:14,760
And then you can easily imagine that there

20
00:01:14,760 --> 00:01:17,250
should be some correspondence between those two things.

21
00:01:17,250 --> 00:01:22,709
For example, your recipe says this step comes before that step.

22
00:01:22,709 --> 00:01:24,209
And then, in the trace,

23
00:01:24,209 --> 00:01:25,814
it looks like it's the other way around.

24
00:01:25,814 --> 00:01:27,269
You should flag that, something's wrong.

25
00:01:27,269 --> 00:01:33,319
Either you lied about the recipe in the workflow or something else at runtime went wrong.

26
00:01:33,319 --> 00:01:36,194
So this is a good mechanism to

27
00:01:36,194 --> 00:01:39,174
really have those two levels play against each other a little bit.

28
00:01:39,174 --> 00:01:41,185
Little bit of redundancy in the system.

29
00:01:41,185 --> 00:01:43,525
Here's how I think about the model

30
00:01:43,525 --> 00:01:46,147
or how I put it together if you have a workflow system,

31
00:01:46,147 --> 00:01:47,609
and here's what actually happened,

32
00:01:47,609 --> 00:01:51,409
and now let's compare. All right!

33
00:01:51,409 --> 00:01:54,555
So this is a comment on provenance standards and tools.

34
00:01:54,555 --> 00:02:00,219
There's a standard that we're going to look briefly at called the W3C PROV standard,

35
00:02:00,219 --> 00:02:05,795
and it provides sort of a minimal model of how you would capture,

36
00:02:05,795 --> 00:02:09,550
or how you would describe rather, retrospective provenance.

37
00:02:09,550 --> 00:02:13,445
So the W3C folks like to just call it provenance.

38
00:02:13,445 --> 00:02:16,284
For them all, typically all provenance is retrospective,

39
00:02:16,284 --> 00:02:18,889
so they don't talk much â€“ the standard doesn't really talk

40
00:02:18,889 --> 00:02:21,754
about the workflow that creates the provenance.

41
00:02:21,754 --> 00:02:24,314
This is we think of actually a shortcoming,

42
00:02:24,314 --> 00:02:27,650
but everybody might have a different workflow system, workflow approach.

43
00:02:27,650 --> 00:02:31,750
So it's not surprising that they didn't take that sort

44
00:02:31,750 --> 00:02:35,882
of scope and they didn't include this in the scope.

45
00:02:35,882 --> 00:02:37,524
They wanted a minimal standard really.

46
00:02:37,524 --> 00:02:41,014
But provenance is currently very much en vogue.

47
00:02:41,014 --> 00:02:44,449
It's a hot research topic.

48
00:02:44,449 --> 00:02:47,469
It's a useful technology,

49
00:02:47,469 --> 00:02:51,294
but there's a problem also with creating provenance.

50
00:02:51,294 --> 00:02:55,317
Right now, it's still difficult to create provenance.

51
00:02:55,317 --> 00:02:57,585
And even if you create it,

52
00:02:57,585 --> 00:02:58,780
how do you use it?

53
00:02:58,780 --> 00:03:01,439
How do you squeeze value out of it?

54
00:03:01,439 --> 00:03:04,219
And so everybody likes to talk about it.

55
00:03:04,219 --> 00:03:06,430
Everybody likes to use somebody else's provenance,

56
00:03:06,430 --> 00:03:07,732
like somebody else's metadata,

57
00:03:07,732 --> 00:03:10,129
but nobody wants to create it in the first place.

58
00:03:10,129 --> 00:03:14,669
And one of the problems is creating it and managing it is still somewhat tedious.

59
00:03:14,669 --> 00:03:17,694
And again, if you don't derive direct value from it for yourself,

60
00:03:17,694 --> 00:03:20,580
you might feel like you can skip this step.

61
00:03:20,580 --> 00:03:22,115
You know, day is short,

62
00:03:22,115 --> 00:03:23,740
there are lots of things to do in my day.

63
00:03:23,740 --> 00:03:25,258
Should I write the next paper,

64
00:03:25,258 --> 00:03:27,165
make the next study?

65
00:03:27,165 --> 00:03:29,439
Or should I document my data more and provide

66
00:03:29,439 --> 00:03:32,404
more provenance so that maybe somebody else can benefit from it?

67
00:03:32,404 --> 00:03:35,169
You can easily see where that decision is going.

68
00:03:35,169 --> 00:03:37,629
So that's why I think, as a community,

69
00:03:37,629 --> 00:03:40,389
it's important those who develop provenance tools and

70
00:03:40,389 --> 00:03:43,419
techniques need to think hard how they can

71
00:03:43,419 --> 00:03:46,449
create tools and techniques that give you

72
00:03:46,449 --> 00:03:48,610
immediate benefit for the people who are

73
00:03:48,610 --> 00:03:51,194
supposed to create the provenance in the first place.

74
00:03:51,194 --> 00:03:54,400
So how can I get some value out of it when I create this provenance,

75
00:03:54,400 --> 00:03:56,199
record it, and so on?

76
00:03:56,199 --> 00:03:58,854
So this is something we're gonna look at a little bit as well.

77
00:03:58,854 --> 00:04:01,930
OK! I call this provenance for self.

78
00:04:01,930 --> 00:04:05,275
So provenance feels like metadata in general.

79
00:04:05,275 --> 00:04:07,734
Metadata feels like often it's for others.

80
00:04:07,734 --> 00:04:09,525
You should document your code,

81
00:04:09,525 --> 00:04:12,414
you should you know your columns and your database schema.

82
00:04:12,414 --> 00:04:14,439
Well it is also for yourself,

83
00:04:14,439 --> 00:04:16,938
but often it doesn't hurt you immediately, it hurts you,

84
00:04:16,938 --> 00:04:18,504
you know, six months in the future,

85
00:04:18,504 --> 00:04:20,095
two years in the future.

86
00:04:20,095 --> 00:04:24,129
Yeah! But if on the other hand you have nice tools that allow

87
00:04:24,129 --> 00:04:28,800
you to do something with your documentation while you're still working on it,

88
00:04:28,800 --> 00:04:30,750
it's a much better incentive to actually use it.

89
00:04:30,750 --> 00:04:32,790
And I think the same is true for provenance.

90
00:04:32,790 --> 00:04:36,730
OK! So here is a simple model that relates

91
00:04:36,730 --> 00:04:42,040
prospective and retrospective provenance that we've used in one of our publications.

92
00:04:42,040 --> 00:04:44,774
So I have a reference there.

93
00:04:44,774 --> 00:04:47,079
As a first approximation,

94
00:04:47,079 --> 00:04:49,485
if you think of a workflow graph as

95
00:04:49,485 --> 00:04:53,800
literally a data flow graph as a diagram where, for example,

96
00:04:53,800 --> 00:05:00,040
steps like, here, the step A and B are connected through data containers,

97
00:05:00,040 --> 00:05:02,115
so for example, your X and Y and Z.

98
00:05:02,115 --> 00:05:04,105
So data X goes into A,

99
00:05:04,105 --> 00:05:06,730
producing Y, Y goes into B,

100
00:05:06,730 --> 00:05:09,074
producing Z. Oh and by the way,

101
00:05:09,074 --> 00:05:12,944
B not only uses the Y but it also uses the original X.

102
00:05:12,944 --> 00:05:14,365
If this is your recipe,

103
00:05:14,365 --> 00:05:17,980
if this is your workflow, then you would expect that at the instance level,

104
00:05:17,980 --> 00:05:21,355
when you look at the actual records and the actual dataset's being processed,

105
00:05:21,355 --> 00:05:23,704
you would see something that looks like that too.

106
00:05:23,704 --> 00:05:28,930
So the dependency at runtime that are logged and traced should

107
00:05:28,930 --> 00:05:35,319
resemble the ones that you have defined ahead of time in your workflow.

108
00:05:35,319 --> 00:05:38,529
And so, mathematically, if you want to get all fancy about it,

109
00:05:38,529 --> 00:05:40,944
you can try and define a homomorphism,

110
00:05:40,944 --> 00:05:43,480
which is sort of a mathematical construct to say

111
00:05:43,480 --> 00:05:46,279
this structure looks like that structure.

112
00:05:46,279 --> 00:05:48,384
And so, if it doesn't,

113
00:05:48,384 --> 00:05:51,519
maybe that's an indication that something went wrong and you can

114
00:05:51,519 --> 00:05:55,639
use that to maybe report what might go wrong.

115
00:05:55,639 --> 00:05:57,693
All right!

116
00:05:57,693 --> 00:05:59,485
Now, I mentioned that

117
00:05:59,485 --> 00:06:04,300
the provenance standard that I haven't really yet talked about but I

118
00:06:04,300 --> 00:06:12,324
will called PROV W3C does not deal with this upper level, with the workflow level.

119
00:06:12,324 --> 00:06:16,100
They only deal with the retrospective provenance level.

120
00:06:16,100 --> 00:06:18,350
They have relationship where, here for example,

121
00:06:18,350 --> 00:06:19,814
I use my own terminology,

122
00:06:19,814 --> 00:06:21,170
this is not standard terminology.

123
00:06:21,170 --> 00:06:25,959
I say read and write because this says that this function call or

124
00:06:25,959 --> 00:06:31,250
active invocation A was reading the X and was writing the Y.

125
00:06:31,250 --> 00:06:32,485
At the workflow level,

126
00:06:32,485 --> 00:06:36,230
maybe I want to use a different terminology so as to not confuse the levels.

127
00:06:36,230 --> 00:06:38,269
Maybe I want to call this in and out.

128
00:06:38,269 --> 00:06:43,100
So the schema workflow level I call something goes in, something goes out.

129
00:06:43,100 --> 00:06:45,139
And then at the actual runtime level,

130
00:06:45,139 --> 00:06:47,295
I call it maybe read and write, for example.

131
00:06:47,295 --> 00:06:50,180
Well, W3C has its own terminology.

132
00:06:50,180 --> 00:06:53,720
For reading, they say used.

133
00:06:53,720 --> 00:06:55,379
So, A used X,

134
00:06:55,379 --> 00:06:57,865
sort of the provenance or

135
00:06:57,865 --> 00:07:01,384
the data dependency direction is sort of in the other direction.

136
00:07:01,384 --> 00:07:04,439
Yeah! So the step A used X,

137
00:07:04,439 --> 00:07:09,800
and then Y was generated by A.

138
00:07:09,800 --> 00:07:11,449
Okay! So instead of write,

139
00:07:11,449 --> 00:07:15,329
you say sort of I write this data or I have written this data you say,

140
00:07:15,329 --> 00:07:17,687
Y was generated by A.

141
00:07:17,687 --> 00:07:18,795
Okay!

142
00:07:18,795 --> 00:07:20,555
That's W3C terminology.

143
00:07:20,555 --> 00:07:26,574
But we felt that it was important to link the prospective provenance graph,

144
00:07:26,574 --> 00:07:28,296
that is the workflow graph,

145
00:07:28,296 --> 00:07:30,404
with a retrospective provenance graph as well.

146
00:07:30,404 --> 00:07:38,959
So we developed a new extension to the PROV model which we call the ProvONE.

147
00:07:38,959 --> 00:07:43,865
We call it ProvONE because we wanted to show the lineage to the PROV standard,

148
00:07:43,865 --> 00:07:45,665
for the W3C PROV standard,

149
00:07:45,665 --> 00:07:47,750
and to the project that sponsored this work,

150
00:07:47,750 --> 00:07:49,415
which is called DataONE.

151
00:07:49,415 --> 00:07:52,800
So PROV standard plus DataONE gives you ProvONE.

152
00:07:52,800 --> 00:07:59,180
Okay? And this is basically slightly hard to decipher a schema here,

153
00:07:59,180 --> 00:08:00,860
but the idea is that, in it,

154
00:08:00,860 --> 00:08:05,045
it contains Trace-land, a retrospective provenance,

155
00:08:05,045 --> 00:08:06,454
which conforms to the standard,

156
00:08:06,454 --> 00:08:09,166
which is the W3C PROV standard,

157
00:08:09,166 --> 00:08:11,300
but then there's a connection to a bunch of

158
00:08:11,300 --> 00:08:15,375
other relationships that we call Workflow-land or prospective provenance.

159
00:08:15,375 --> 00:08:18,199
And then also we have some little bit more information about

160
00:08:18,199 --> 00:08:21,815
the extra data structures being talked about.

161
00:08:21,815 --> 00:08:24,410
Okay? All right!

162
00:08:24,410 --> 00:08:28,560
So I'll go into these details in the next lecture.

163
00:08:28,560 --> 00:08:34,215
But for now, I just want to come back to this point of provenance for self.

164
00:08:34,215 --> 00:08:38,789
So, right now, what we see is there are these data products out there.

165
00:08:38,789 --> 00:08:41,129
For example, here this is a national climate assessment from

166
00:08:41,129 --> 00:08:45,164
a few years ago that was put together with a lot of effort by a lot of people,

167
00:08:45,164 --> 00:08:50,309
and they tried to do a good job with respect to sourcing their findings.

168
00:08:50,309 --> 00:08:52,805
So they try to put all the provenance information there,

169
00:08:52,805 --> 00:08:57,629
and they even created a whole online information system or online database,

170
00:08:57,629 --> 00:09:00,534
GCIS, the Global Change Information System.

171
00:09:00,534 --> 00:09:02,805
And in that Global Change Information System,

172
00:09:02,805 --> 00:09:04,394
here's a snapshot of it.

173
00:09:04,394 --> 00:09:06,942
When they had a finding like a graph,

174
00:09:06,942 --> 00:09:09,144
they had lots of metadata about it, they say okay,

175
00:09:09,144 --> 00:09:12,894
this graph talks about this region, maybe Texas,

176
00:09:12,894 --> 00:09:18,715
here and it is about maybe record heat and drought in Texas in summer 2011.

177
00:09:18,715 --> 00:09:24,034
And they wanted to document how they have created this particular plot here.

178
00:09:24,034 --> 00:09:26,669
And so, again, I'll have more details on that,

179
00:09:26,669 --> 00:09:30,114
but they might show that this particular dataset was derived

180
00:09:30,114 --> 00:09:34,110
from this other dataset or input using this particular script.

181
00:09:34,110 --> 00:09:37,590
So they were pulling together provenance records,

182
00:09:37,590 --> 00:09:40,919
documenting basically what was done.

183
00:09:40,919 --> 00:09:43,649
But this feels a little bit like pulling teeth,

184
00:09:43,649 --> 00:09:47,340
running after the scientists who've done these studies, e-mailing them,

185
00:09:47,340 --> 00:09:49,605
contacting them, or looking at their papers,

186
00:09:49,605 --> 00:09:51,460
trying to put everything together.

187
00:09:51,460 --> 00:09:55,019
It sort of feels a little bit like reverse engineering or screen scraping.

188
00:09:55,019 --> 00:09:57,865
There's some data out there and we're looking just

189
00:09:57,865 --> 00:10:01,365
in the wrong place because that's the only place we have.

190
00:10:01,365 --> 00:10:04,215
And one of the reasons that people don't

191
00:10:04,215 --> 00:10:07,845
create more provenance on the fly and share it that,

192
00:10:07,845 --> 00:10:08,904
well, there's a lot of reasons.

193
00:10:08,904 --> 00:10:11,950
There's barely a standard out there when we haven't standard out there.

194
00:10:11,950 --> 00:10:13,335
But in terms of tool support,

195
00:10:13,335 --> 00:10:15,735
it's very much missing.

196
00:10:15,735 --> 00:10:20,220
And then also, even if you work in this area and you want

197
00:10:20,220 --> 00:10:24,975
to source and document what you're doing and provide this provenance information,

198
00:10:24,975 --> 00:10:27,269
it still feels like it benefits others.

199
00:10:27,269 --> 00:10:30,735
This is why I have here this fellow sitting here somewhat frustrated,

200
00:10:30,735 --> 00:10:36,509
saying "well, where's my value that I get of creating provenance?"

201
00:10:36,509 --> 00:10:40,889
So we want to prime the pump and create more provenance information by

202
00:10:40,889 --> 00:10:46,125
letting scientists themselves benefit from the provenance they create.

203
00:10:46,125 --> 00:10:48,679
So, currently, while we have tools for

204
00:10:48,679 --> 00:10:52,460
capturing provenance and we can even share and link the provenance,

205
00:10:52,460 --> 00:10:58,325
but the individual scientists who supposed to to create it for their own data they work,

206
00:10:58,325 --> 00:11:01,720
they don't have much tools there.

207
00:11:01,720 --> 00:11:05,639
So that's the idea of some of the research that's being done is how

208
00:11:05,639 --> 00:11:09,965
can we create provenance that's valuable.

209
00:11:09,965 --> 00:11:13,259
So they can use it in their own studies while they do the work.

210
00:11:13,259 --> 00:11:16,429
Maybe if I have some powerful provenance queries,

211
00:11:16,429 --> 00:11:19,335
maybe I can improve the quality of my findings.

212
00:11:19,335 --> 00:11:22,769
Maybe I detect the mistake before somebody else does.

213
00:11:22,769 --> 00:11:25,159
A year after I published my study,

214
00:11:25,159 --> 00:11:28,609
a mistake is found and,

215
00:11:28,609 --> 00:11:30,620
you know, maybe I could have caught this

216
00:11:30,620 --> 00:11:33,485
myself if I had better provenance support, for example.

217
00:11:33,485 --> 00:11:36,524
Or maybe just my studies,

218
00:11:36,524 --> 00:11:39,524
I can compile it faster if I have tools

219
00:11:39,524 --> 00:11:45,220
that allow me to more systematically steer my experiments.