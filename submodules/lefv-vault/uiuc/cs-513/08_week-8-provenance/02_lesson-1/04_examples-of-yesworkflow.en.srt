1
00:00:00,000 --> 00:00:08,407
[MUSIC]

2
00:00:08,407 --> 00:00:13,312
[SOUND] Now let me show you a couple
of examples just to show that this is

3
00:00:13,312 --> 00:00:15,132
practically feasible.

4
00:00:15,132 --> 00:00:20,482
So here is a workflow
diagram that was created for

5
00:00:20,482 --> 00:00:25,680
a script from a collaboration
called MsTMIP.

6
00:00:25,680 --> 00:00:30,900
So that's Multiscale Synthesis and
Terrestrial Model Intercomparison Project.

7
00:00:30,900 --> 00:00:36,620
So this a project where climate
scientists compare their simulation

8
00:00:36,620 --> 00:00:40,660
models against one another, to kind of
comparing it against the benchmark and

9
00:00:40,660 --> 00:00:43,680
sort of ranking the models,
comparing the models.

10
00:00:43,680 --> 00:00:47,130
And in this context,
there are various scripts being used.

11
00:00:47,130 --> 00:00:49,810
And again if you want to explain
what the script is doing,

12
00:00:49,810 --> 00:00:53,390
then looking at the diagram like that
gives you quickly a high level overview.

13
00:00:53,390 --> 00:00:57,250
And also you see data dependencies
quite nicely that way.

14
00:00:57,250 --> 00:01:02,080
Again this comes from the DataONE project,
he has a very different use case.

15
00:01:02,080 --> 00:01:05,710
Here is bioinformatics
use case once again.

16
00:01:05,710 --> 00:01:11,550
In this case, the scientist is
interested really in the step.

17
00:01:11,550 --> 00:01:17,253
So it emphasizes the green box is here,
the computational steps and

18
00:01:17,253 --> 00:01:22,570
the data is sort of somewhat demoted
to just a label on the edge.

19
00:01:23,820 --> 00:01:26,550
So some people prefer this kind of

20
00:01:26,550 --> 00:01:30,820
diagram to quickly give a high
level overview what's going on.

21
00:01:30,820 --> 00:01:33,950
So in this case, you see there's
four green boxes, four steps.

22
00:01:33,950 --> 00:01:35,800
One is called normalize, stands for

23
00:01:35,800 --> 00:01:39,270
the normalization of data
across microarray datasets.

24
00:01:39,270 --> 00:01:42,690
So if you're in that domain,
this means something to you?

25
00:01:42,690 --> 00:01:45,690
Then you have maybe a selection
of differentially expressed genes

26
00:01:45,690 --> 00:01:46,950
between conditions.

27
00:01:46,950 --> 00:01:51,050
Again as a bioinformatician,
it's clear what's going on there.

28
00:01:52,050 --> 00:01:56,320
And then maybe you have determination
of gene ontology statistics for

29
00:01:56,320 --> 00:01:58,350
the result of data set.

30
00:01:58,350 --> 00:02:01,105
So GO stands for the gene ontology.

31
00:02:01,105 --> 00:02:05,872
And then maybe you create a Heatmap at
the end that is basically the final

32
00:02:05,872 --> 00:02:08,650
product of the data analysis.

33
00:02:08,650 --> 00:02:13,330
So it's rather easy to create such a
diagram and you can put it on your paper.

34
00:02:13,330 --> 00:02:15,880
But as we shall see it's not
just something you look at,

35
00:02:15,880 --> 00:02:17,590
it's going to be an artifact itself.

36
00:02:17,590 --> 00:02:21,600
A knowledge artifact that you can then
further use to ask questions about.

37
00:02:21,600 --> 00:02:26,763
So to illustrate a YesWorkflow a little
bit more, I'm going to use this example,

38
00:02:26,763 --> 00:02:30,707
which comes from something
that's implemented in Python.

39
00:02:30,707 --> 00:02:33,182
It simulates a physical workflow,

40
00:02:33,182 --> 00:02:39,049
a data collection workflow in the context
of something called X-ray diffraction.

41
00:02:39,049 --> 00:02:40,528
And as we shall see,

42
00:02:40,528 --> 00:02:45,837
this is a somewhat more complex script
that if you model it as a workflow,

43
00:02:45,837 --> 00:02:51,160
you can get additional understanding
of what's going on in the script.

44
00:02:53,950 --> 00:02:58,478
So imagine you have created and I'm
going to show this in a separate demo of

45
00:02:58,478 --> 00:03:05,670
this, how to create the workflow
using the tools, workflow diagrams.

46
00:03:05,670 --> 00:03:11,970
But once you have that,
you can query the prospective problems,

47
00:03:11,970 --> 00:03:15,340
you can query this workflow diagram or you
can even connect it to retrospective font.

48
00:03:15,340 --> 00:03:18,530
I want to show you this briefly,
how that works.

49
00:03:18,530 --> 00:03:23,270
So we call this approach
YesWorkflow recon or YW-RECON for

50
00:03:23,270 --> 00:03:30,309
reconstructing retrospective provenance
and linking it to prospective provenance.

51
00:03:30,309 --> 00:03:33,700
And sometimes we can get this almost for
free.

52
00:03:33,700 --> 00:03:35,940
So although we're not
using a workflow system,

53
00:03:35,940 --> 00:03:40,690
we can often harvest some
provenance information just by

54
00:03:40,690 --> 00:03:46,890
declaring certain connections between the
data files that the script uses on disk.

55
00:03:46,890 --> 00:03:49,540
And the conceptual model that
we've created that YesWorkflow

56
00:03:49,540 --> 00:03:50,570
diagram that you see on the left.

57
00:03:52,520 --> 00:03:57,580
So what you can do, and again I'm
going to show at a close up soon.

58
00:03:57,580 --> 00:04:02,210
Is we can declare for certain data
element, these are the yellow boxes.

59
00:04:02,210 --> 00:04:05,942
We can declare how they link to
artifacts that the script uses,

60
00:04:05,942 --> 00:04:09,070
namely files that the script uses on disk.

61
00:04:09,070 --> 00:04:12,990
And by making that link we're
going to we call this URI-templates.

62
00:04:12,990 --> 00:04:17,220
So it's basically a little bit
like a path expression that points

63
00:04:17,220 --> 00:04:21,530
into the file system or it could point to
URL, it could point to place on the web.

64
00:04:21,530 --> 00:04:24,340
It says, this data item that
I'm talking about here.

65
00:04:24,340 --> 00:04:26,820
Here's the URL or here's the URI and

66
00:04:26,820 --> 00:04:32,130
in this particular case the URI-template
describes the structure of that data.

67
00:04:32,130 --> 00:04:35,230
It's typically in some sort
of folder structure, and

68
00:04:35,230 --> 00:04:37,020
this is what you see on the right.

69
00:04:37,020 --> 00:04:40,490
So on the right you see,
basically a directory tree or

70
00:04:40,490 --> 00:04:46,990
folder tree that shows how this particular
script, the workflow organises the data.

71
00:04:46,990 --> 00:04:51,970
So at the top, you see there's a run
folder, maybe you have multiple

72
00:04:51,970 --> 00:04:55,050
runs of your workflow,
multiple runs of your experiments.

73
00:04:55,050 --> 00:04:57,440
And then there's subfolders
on the top near the top,

74
00:04:57,440 --> 00:04:59,030
you see something called raw.

75
00:04:59,030 --> 00:05:01,750
This is for raw images, and
then closer to the bottom,

76
00:05:01,750 --> 00:05:04,380
you see something that's called data.

77
00:05:04,380 --> 00:05:08,040
This is for the data produced
by the script, so this is for

78
00:05:08,040 --> 00:05:10,240
the transformed images.

79
00:05:10,240 --> 00:05:14,230
So often data is really organized
into these collections and

80
00:05:14,230 --> 00:05:16,750
you can map these collections
into folders on disk.

81
00:05:18,210 --> 00:05:21,450
And now wouldn't it be interesting
if I could look at these files

82
00:05:21,450 --> 00:05:25,450
that are generated, consumed and
produced by this script.

83
00:05:25,450 --> 00:05:29,040
And I could link that to my
conceptual model that I've created.

84
00:05:29,040 --> 00:05:31,080
This is something we
can do with this tool.

85
00:05:31,080 --> 00:05:33,790
So again, in the first step you
would have annotated your script

86
00:05:33,790 --> 00:05:37,348
to create a YesWorkflow model, so
we've talked about this already.

87
00:05:37,348 --> 00:05:40,860
So we're kind of past that step, but
we assume you have already done this.

88
00:05:40,860 --> 00:05:45,300
You mark the beginning and end of a step,
and the input and output and

89
00:05:45,300 --> 00:05:48,690
then things are connected
up that way by the system.

90
00:05:48,690 --> 00:05:50,510
Now you run the script.

91
00:05:50,510 --> 00:05:53,590
Once you've run the script of course,
files are read and written.

92
00:05:53,590 --> 00:05:56,300
Now we're sort of in
the retrospective provenance land.

93
00:05:56,300 --> 00:05:59,400
Because now after the script run,
stuff has happened.

94
00:05:59,400 --> 00:06:01,938
And so we can look at the artifacts
that were left behind.

95
00:06:01,938 --> 00:06:06,866
And we try to now connect them to the
model that we've created ahead of time to

96
00:06:06,866 --> 00:06:08,489
the prospective model.

97
00:06:08,489 --> 00:06:10,064
[COUGH] And in order to do this,

98
00:06:10,064 --> 00:06:14,160
we kind of invoke a particular function
of the CS workflow tool called recon.

99
00:06:15,440 --> 00:06:19,300
And what the tool does then at this point,
it looks in the model,

100
00:06:19,300 --> 00:06:24,870
looks at the URI-templates and
finds the corresponding items on disk.

101
00:06:24,870 --> 00:06:27,710
And then sort of builds that bridge
between the retrospective and

102
00:06:27,710 --> 00:06:29,710
the prospective provenance.

103
00:06:29,710 --> 00:06:34,560
And then subsequently,
you can now query the combined model.

104
00:06:35,590 --> 00:06:38,810
And I'm going to show you with some
examples, what is meant with that,

105
00:06:38,810 --> 00:06:42,470
why that is a good idea and
how you can get some value out of this.

106
00:06:42,470 --> 00:06:46,360
So let's look at this data
collection workflow again.

107
00:06:46,360 --> 00:06:51,220
So on the left, you have the workflow
diagram and then on the right,

108
00:06:51,220 --> 00:06:55,490
you have the artifacts left behind
by the execution of the script.

109
00:06:55,490 --> 00:06:57,290
So again,
the first step was to create the model.

110
00:06:58,450 --> 00:07:01,680
The second step is to run the script and

111
00:07:01,680 --> 00:07:03,990
to look at then the metadata
that you see at the right.

112
00:07:05,020 --> 00:07:06,480
And what does this allow you to do?

113
00:07:06,480 --> 00:07:10,210
It allows you to ask questions about
the processing history and data lineage.

114
00:07:11,210 --> 00:07:14,250
So you would like to know
certain things about your data.

115
00:07:14,250 --> 00:07:19,210
Well, because you have created
this model and you have connected

116
00:07:19,210 --> 00:07:24,050
the model to the trace information,
to the retrospective problems information.

117
00:07:24,050 --> 00:07:27,940
In this case, it's really just
the files that are left behind on disk,

118
00:07:27,940 --> 00:07:31,270
not left behind but are left on disk,
but executing the script.

119
00:07:31,270 --> 00:07:33,940
You can now answer certain
questions that previously

120
00:07:33,940 --> 00:07:35,420
you would not be able to answer.

121
00:07:35,420 --> 00:07:38,450
Previously you would have
to browse those folders,

122
00:07:38,450 --> 00:07:42,240
navigate those folders and
try to make sense of it.

123
00:07:42,240 --> 00:07:46,490
But now it's rather explicit, so there are
queries that are now associated with your

124
00:07:46,490 --> 00:07:52,530
experiment, with your workflow or your
script, and these queries can be executed.

125
00:07:52,530 --> 00:07:55,060
So you can look at the queries and you can
look at the results of the queries, and

126
00:07:55,060 --> 00:07:58,540
then they tell you something
about the processing history.

127
00:07:58,540 --> 00:07:59,320
So for example,

128
00:07:59,320 --> 00:08:04,870
you might have this question, what samples
did this script run collect images from?

129
00:08:04,870 --> 00:08:09,730
So again for context here this is a
workflow model of a script that simulates

130
00:08:09,730 --> 00:08:14,350
the collection of data from
an X-ray defraction experiment.

131
00:08:14,350 --> 00:08:18,543
Where basically cassettes
are put into some sort of

132
00:08:18,543 --> 00:08:23,624
instrumental set up where images
are taken at high voltages.

133
00:08:23,624 --> 00:08:26,145
And then the X-ray crystallographers,

134
00:08:26,145 --> 00:08:30,897
what they're trying to do is they try to
infer something about the structure of

135
00:08:30,897 --> 00:08:36,260
the crystals in the molecular structure
based on the defraction images they see.

136
00:08:36,260 --> 00:08:40,800
So there's some rather famous defraction
images that you might know about.

137
00:08:40,800 --> 00:08:43,390
If you are a little bit
interested in biology,

138
00:08:43,390 --> 00:08:46,580
you might know something
about the history how

139
00:08:46,580 --> 00:08:51,569
the structure of DNA also called
the secret of life how that was uncovered.

140
00:08:52,720 --> 00:08:56,706
It involves certain gentlemen
by the name of Crick and Watson.

141
00:08:56,706 --> 00:09:00,745
And also female scientists
Rosalind Franklin,

142
00:09:00,745 --> 00:09:06,063
who actually took the pictures
that helped these two guys figure

143
00:09:06,063 --> 00:09:11,300
out how DNAs put together actually
as the double helix, okay?

144
00:09:11,300 --> 00:09:15,220
So that's actually an interesting
science story that you can read about.

145
00:09:15,220 --> 00:09:20,540
So we're talking about an instrument that
does extra diffractioning images to figure

146
00:09:20,540 --> 00:09:28,850
out structures of crystals, and
this is the workflow that goes with it.

147
00:09:28,850 --> 00:09:32,880
And so as part of this workflow,
images are being taken.

148
00:09:32,880 --> 00:09:36,653
So there's data about samples that
are put under the instrument.

149
00:09:36,653 --> 00:09:41,598
And then we have to decide based maybe
on some quality measures, should we

150
00:09:41,598 --> 00:09:47,410
take another picture, should we take
another image of this sample and so on.

151
00:09:47,410 --> 00:09:49,790
So in particular this question,

152
00:09:49,790 --> 00:09:52,920
what samples did the script
run collect images from?

153
00:09:52,920 --> 00:09:54,090
So what were the samples?

154
00:09:54,090 --> 00:09:57,560
We want to answer this question, and
because we've created this model.

155
00:09:57,560 --> 00:10:02,330
We can now look both in the diagram
on the left of the Workflow model,

156
00:10:02,330 --> 00:10:05,280
but then also connect it
to the data that's on disk.

157
00:10:05,280 --> 00:10:10,364
So we would see this understand that
there's a certain folder level,

158
00:10:10,364 --> 00:10:15,027
maybe two folders down or so,
that corresponds to the samples.

159
00:10:15,027 --> 00:10:17,260
We would know this from
the model on the left.

160
00:10:17,260 --> 00:10:21,430
So the model on the left tells us,
go here, look what folders are there, and

161
00:10:21,430 --> 00:10:23,260
those are your samples.

162
00:10:23,260 --> 00:10:26,350
So the connection is made by declaring

163
00:10:28,610 --> 00:10:32,320
inside of your model
a certain URI-template, and

164
00:10:32,320 --> 00:10:35,550
what you cannot see because it's
a little small thumbnail here.

165
00:10:35,550 --> 00:10:40,528
But it is basically like
a path expression, so

166
00:10:40,528 --> 00:10:44,876
it looks like a directory path a/b/c.

167
00:10:44,876 --> 00:10:49,861
And then you have this curly braces
in the path expression there that

168
00:10:49,861 --> 00:10:51,970
makes it really a template.

169
00:10:51,970 --> 00:10:58,260
And that says, okay, at this level I have
samples, yeah, so the sample identifier.

170
00:10:58,260 --> 00:11:01,684
So the folder name
corresponds to this artifact

171
00:11:01,684 --> 00:11:05,210
in the URI-template in
the YesWorkflow model.

172
00:11:05,210 --> 00:11:08,390
Let's say you want to know, okay, so
what were the energies that were used for

173
00:11:08,390 --> 00:11:11,440
a particular image collection
from this particular sample?

174
00:11:11,440 --> 00:11:14,400
So let's say, you have a particular
sample identified which you know

175
00:11:14,400 --> 00:11:17,720
is in a certain folder
in your directory tree.

176
00:11:17,720 --> 00:11:21,530
And the sample is maybe called DRT322, and

177
00:11:21,530 --> 00:11:24,050
now you want to know well what
were the energies used for that?

178
00:11:25,110 --> 00:11:30,240
Yeah, this information is somehow
embedded often in practice,

179
00:11:30,240 --> 00:11:31,990
in file names and folder names.

180
00:11:33,310 --> 00:11:35,770
It's maybe not always
the ideal way to do it, but

181
00:11:35,770 --> 00:11:38,740
it's actually very practical way for
the scientist to keep some sort

182
00:11:38,740 --> 00:11:43,200
of organization about the data
that often sits in files.

183
00:11:43,200 --> 00:11:47,020
Your more often than not data does not
live in a database as we wished it does.

184
00:11:47,020 --> 00:11:51,500
But for various reasons, including
flexibility, convenience and so on,

185
00:11:51,500 --> 00:11:56,350
sometimes scalability data just
sits in files, on the file system.

186
00:11:56,350 --> 00:12:00,570
But you need to put some organization
to it, so if you have some nice

187
00:12:00,570 --> 00:12:04,870
hierarchical organization and
you have a naming convention.

188
00:12:04,870 --> 00:12:08,194
But then you can use that information
quickly, get it back out, and

189
00:12:08,194 --> 00:12:10,510
answer those kinds of questions.

190
00:12:10,510 --> 00:12:13,620
So if we want to know what energies
were used for image collection,

191
00:12:13,620 --> 00:12:18,110
from this particular sample,
we can see this information.

192
00:12:18,110 --> 00:12:23,480
It is left behind so to say, by the script
in the form of folders names or

193
00:12:23,480 --> 00:12:27,680
parts of names of folders or files, okay?

194
00:12:27,680 --> 00:12:31,090
So in this particular case, the sample,

195
00:12:31,090 --> 00:12:35,320
we already know is somewhere in the
directory structure at a certain level.

196
00:12:36,760 --> 00:12:40,341
We look at the folder name and
that's DRT322,

197
00:12:40,341 --> 00:12:44,358
well that's the particular
sample data is below that.

198
00:12:44,358 --> 00:12:51,690
And then it has subfolders, which collect
image data at different energy level.

199
00:12:51,690 --> 00:12:57,240
So here we see, probably barely see
that there are two different subfolders.

200
00:12:57,240 --> 00:13:01,451
One called E 10,000 and
the other one E 11,000.

201
00:13:01,451 --> 00:13:07,130
And these are their voltage electron
volts at which the image was taken.

202
00:13:07,130 --> 00:13:12,420
So the image is taken at 10,000
volts would be in one subfolder,

203
00:13:12,420 --> 00:13:15,310
and the ones at 11,000
would be another subfolder.

204
00:13:15,310 --> 00:13:18,270
So by keeping things
nicely separate that way,

205
00:13:18,270 --> 00:13:22,780
you can just look at the folder structure
and again you know this information.

206
00:13:22,780 --> 00:13:25,090
And how did we make that connection?

207
00:13:25,090 --> 00:13:30,300
Well in the model, we explicitly modeled
the fact that samples are the certain

208
00:13:30,300 --> 00:13:36,030
folder level and then energies
are at the subfolder level of that.

209
00:13:36,030 --> 00:13:40,870
So think of this again as a path
expression that has folder names and

210
00:13:40,870 --> 00:13:42,170
subfolder names.

211
00:13:42,170 --> 00:13:45,770
And it's a URI-template,so there's
no hard wired name there, but

212
00:13:45,770 --> 00:13:47,483
we put sorts of a variable there.

213
00:13:47,483 --> 00:13:50,858
We'll say, okay,
her's parameter that you like or

214
00:13:50,858 --> 00:13:56,670
a variable that indicates whatever you
find at that level and the hierarchy.

215
00:13:56,670 --> 00:13:59,990
Those names think of them as sample IDs.

216
00:13:59,990 --> 00:14:04,450
And into the sub folder, think of
those names as encoding the electron,

217
00:14:06,630 --> 00:14:10,240
the energy level at which
the image was taken.

218
00:14:10,240 --> 00:14:14,600
And so it goes again, you can ask all
kinds of detailed questions there.

219
00:14:14,600 --> 00:14:19,480
For example, you might now want to trace
a particular data lineage of your script.

220
00:14:19,480 --> 00:14:25,005
So if you want to know, okay, where's
the raw image of the corrected image

221
00:14:25,005 --> 00:14:30,580
DRT322_11000 electron volt and
then frame number 30.

222
00:14:30,580 --> 00:14:33,481
Okay, so where is the raw image for that?

223
00:14:33,481 --> 00:14:38,058
So there is a step called transform
images near the bottom of this workflow,

224
00:14:38,058 --> 00:14:41,150
basically near the end of the script.

225
00:14:41,150 --> 00:14:45,380
Corrected image, corrected images pop out,
there is some sort of image transformation

226
00:14:45,380 --> 00:14:48,380
that happens, but you want to
see the original image for that.

227
00:14:49,390 --> 00:14:50,800
How would you know that?

228
00:14:50,800 --> 00:14:54,430
Well in this case, again the data
has been organized in a certain way.

229
00:14:54,430 --> 00:14:57,440
So the file name gives away
a lot of the metadata.

230
00:14:58,640 --> 00:15:03,180
And what the YesWorkflow tool does,
it allows you to say, what is

231
00:15:03,180 --> 00:15:07,910
the pattern by which you have encoded this
important metadata into the file name?

232
00:15:07,910 --> 00:15:12,153
So we can extract that and make it,
so give it back to you and

233
00:15:12,153 --> 00:15:15,200
now you can ask questions about it.

234
00:15:15,200 --> 00:15:19,670
We would know from the file name, these
three different pieces of information.

235
00:15:19,670 --> 00:15:23,180
The sample ID, the energy level, and

236
00:15:23,180 --> 00:15:27,040
in this case the frame number,
so this was frame number of 30.

237
00:15:27,040 --> 00:15:31,130
And now, because we have that model,
we can kind of point to another file

238
00:15:32,810 --> 00:15:38,690
that was used as the raw
image of this output result.

239
00:15:38,690 --> 00:15:41,620
So because we have the pieces of metadata,

240
00:15:41,620 --> 00:15:44,760
we can now look in another
folder somewhere else.

241
00:15:44,760 --> 00:15:48,450
And we find the same sample ID,
we find the same energy level,

242
00:15:48,450 --> 00:15:50,740
we find the same frame number.

243
00:15:50,740 --> 00:15:56,800
And the model tells us,
well that this raw image file,

244
00:15:56,800 --> 00:15:59,200
taken from that sample,
taken at this energy level.

245
00:15:59,200 --> 00:16:02,850
This frame number gave rise
to this transformed image

246
00:16:04,410 --> 00:16:07,270
that has undergone this
image transformation step.

247
00:16:07,270 --> 00:16:11,890
The fact that I can see this at
the retrospective provenance level,

248
00:16:11,890 --> 00:16:14,710
in this case at the level
of files on disc.

249
00:16:14,710 --> 00:16:19,840
Is really facilitated by having in
the model a corresponding relationship

250
00:16:19,840 --> 00:16:24,840
between the outputs of the transform
image step and the inputs of that step.

251
00:16:26,000 --> 00:16:30,337
I use a similar URI-template,
I've made this connection explicit.

252
00:16:30,337 --> 00:16:34,520
In my workflow diagram, I said okay,
here's a step that consumes this data.

253
00:16:34,520 --> 00:16:36,450
This is how this data is laid out.

254
00:16:36,450 --> 00:16:40,330
It's consumed by this step and
it gives rise to a new set of data

255
00:16:40,330 --> 00:16:44,400
in another subfolder structure,
and here is the correspondents.

256
00:16:44,400 --> 00:16:46,330
So I have the correspondence in the model.

257
00:16:46,330 --> 00:16:47,900
Because I have it in the model,

258
00:16:47,900 --> 00:16:53,730
I can now harvest it on this can see
the instances of that relationship.

259
00:16:53,730 --> 00:16:55,720
And therefore,
I can answer the questions that I have.

260
00:16:55,720 --> 00:16:58,710
And here's a final example, just briefly,

261
00:16:58,710 --> 00:17:04,460
what cassette-id had the sample leading
to this particular output product?

262
00:17:05,550 --> 00:17:13,280
And again, you see the connection is
sort of anticipated in the model.

263
00:17:13,280 --> 00:17:15,000
So you see it through these circled ovals,

264
00:17:15,000 --> 00:17:17,500
there's these expressions that
correspond to one another.

265
00:17:17,500 --> 00:17:20,810
And in this case, you can go all
the way back to the overall input.

266
00:17:20,810 --> 00:17:24,960
So cassette-id is a global input
to this overall workflow or

267
00:17:24,960 --> 00:17:26,610
to this overall script.

268
00:17:26,610 --> 00:17:31,755
So it's all nicely connected
up in the model, and

269
00:17:31,755 --> 00:17:36,920
therefore become queriable
in this provenance.

270
00:17:36,920 --> 00:17:43,050
So what I've shown so far is really two
kinds of provenance information together,

271
00:17:43,050 --> 00:17:44,700
kind of very loosely coupled.

272
00:17:44,700 --> 00:17:47,690
One is the YesWorkflow model,
the diagram that I've shown to you.

273
00:17:47,690 --> 00:17:51,460
You think of it as prospective provenance,
sometimes I call it workflow land.

274
00:17:51,460 --> 00:17:55,300
It's basically that general recipe and
then it has the retrospective provenance

275
00:17:55,300 --> 00:17:58,870
or what I like to call
it sometimes traceland.

276
00:17:58,870 --> 00:18:03,340
The things, the artifacts that really
well left behind, runtime observables,

277
00:18:03,340 --> 00:18:06,110
filenames and so on there on disk.

278
00:18:06,110 --> 00:18:09,110
So this connection here has
been made in a certain way.

279
00:18:10,640 --> 00:18:15,500
I like to think of it on the cheap,
because the script

280
00:18:15,500 --> 00:18:20,290
that we were executing here did not
have a specific provenance recorder.

281
00:18:21,470 --> 00:18:22,830
It's really just all in the model.

282
00:18:22,830 --> 00:18:24,600
The information's all in the model and

283
00:18:24,600 --> 00:18:28,550
in the artifacts left behind by the script
in the file names and folder names.

284
00:18:28,550 --> 00:18:30,180
No additional recording was done.

285
00:18:30,180 --> 00:18:33,710
Which is kind of neat, it says,
I can tell something about the history

286
00:18:35,130 --> 00:18:38,450
of the processing history
of my data artifacts.

287
00:18:38,450 --> 00:18:44,190
Simply by exploiting the structure
of these artifacts on disk and

288
00:18:44,190 --> 00:18:47,219
having some of the knowledge
encoded in my model.

289
00:18:49,240 --> 00:18:53,763
So that's nice that I can uncover or
recover or reconstruct some

290
00:18:53,763 --> 00:18:58,551
provenance just from files and
folders and the YesWorkflow model.

291
00:18:58,551 --> 00:19:08,551
[MUSIC]