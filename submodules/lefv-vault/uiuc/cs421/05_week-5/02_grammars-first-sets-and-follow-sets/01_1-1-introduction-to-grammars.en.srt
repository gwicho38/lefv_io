1
00:00:00,000 --> 00:00:03,585
Hello. Welcome to CS 421.

2
00:00:03,585 --> 00:00:07,065
We're going to start a new section of the course with this video.

3
00:00:07,065 --> 00:00:08,940
In the first section of the course,

4
00:00:08,940 --> 00:00:12,630
we were concerned with writing programs to represent languages and you learned about

5
00:00:12,630 --> 00:00:13,980
different kinds of recursion and

6
00:00:13,980 --> 00:00:17,010
programming techniques such as continuation passing style,

7
00:00:17,010 --> 00:00:20,265
and you learned about algebraic data types and type classes.

8
00:00:20,265 --> 00:00:23,010
But now, we're going to talk about how the computer reads

9
00:00:23,010 --> 00:00:26,520
these computer programs and turns them into a form it can process.

10
00:00:26,520 --> 00:00:30,810
First thing we need to do if we're going to teach a computer to read textual input,

11
00:00:30,810 --> 00:00:32,370
process it as a language,

12
00:00:32,370 --> 00:00:36,160
is to have a way to specify formally what the language looks like.

13
00:00:36,160 --> 00:00:38,910
We do this with the notation called a grammar.

14
00:00:38,910 --> 00:00:40,990
So, when you're done with this video,

15
00:00:40,990 --> 00:00:43,955
you'll be able to identify the different parts of a grammar.

16
00:00:43,955 --> 00:00:47,870
You'll be able identify that terminal and non-terminal symbols, sentences,

17
00:00:47,870 --> 00:00:52,240
and productions, and use a grammar to generate something called the parse tree.

18
00:00:52,240 --> 00:00:53,870
You'll be able to identify grammars have

19
00:00:53,870 --> 00:00:56,929
certain properties such as being left- recursive or ambiguous,

20
00:00:56,929 --> 00:01:00,905
and demonstrate why it's important to know such things.

21
00:01:00,905 --> 00:01:04,970
Here's the problem we're trying to solve for this part of the course.

22
00:01:04,970 --> 00:01:08,180
So, a programmer usually types in a program using

23
00:01:08,180 --> 00:01:12,605
a text editor and saves it as ASCII text or perhaps some variant of unicode.

24
00:01:12,605 --> 00:01:16,490
Now, this representation is fundamentally a stream of characters.

25
00:01:16,490 --> 00:01:18,860
It's difficult to process this directly

26
00:01:18,860 --> 00:01:21,050
if we want to treat it as a computer program though.

27
00:01:21,050 --> 00:01:23,750
So, by now, you'll have written some interpreters that

28
00:01:23,750 --> 00:01:26,510
process abstract syntax trees directly.

29
00:01:26,510 --> 00:01:31,820
What we want is a way to convert the text into these abstract syntax trees.

30
00:01:31,820 --> 00:01:36,650
In Haskell, descendance from the previous slide might be represented like this.

31
00:01:36,650 --> 00:01:39,440
We have some user-defined data type and

32
00:01:39,440 --> 00:01:42,890
a separate constructor for each of the language components.

33
00:01:42,890 --> 00:01:46,160
The mechanism for converting a block of text into

34
00:01:46,160 --> 00:01:50,150
an abstract syntax tree is usually referred to as parsing.

35
00:01:50,150 --> 00:01:53,465
Usually, this is broken down into two distinct steps.

36
00:01:53,465 --> 00:01:56,675
The first step is to take the incoming stream of characters

37
00:01:56,675 --> 00:02:00,245
and break them up into individual words or tokens.

38
00:02:00,245 --> 00:02:03,680
The tokens indicate not just the word but the kind of word.

39
00:02:03,680 --> 00:02:05,640
For example, the string one, two,

40
00:02:05,640 --> 00:02:08,149
three will be converted into an integer token,

41
00:02:08,149 --> 00:02:11,390
and the string else will be converted into the else keyword token.

42
00:02:11,390 --> 00:02:14,840
This phase is called lexing or scanning.

43
00:02:14,840 --> 00:02:17,210
The next phase is called parsing.

44
00:02:17,210 --> 00:02:20,600
This is where individual words get combined into sentences.

45
00:02:20,600 --> 00:02:23,420
The word parsing can be used in two different ways here.

46
00:02:23,420 --> 00:02:25,700
Sometimes, it includes the lexing step and

47
00:02:25,700 --> 00:02:29,420
refers to the whole process of converting the text to a tree,

48
00:02:29,420 --> 00:02:34,130
and sometimes, it simply refers to the part where we convert the token stream to a tree.

49
00:02:34,130 --> 00:02:38,215
Usually, it's clear from context which one we intend them.

50
00:02:38,215 --> 00:02:39,920
So, in order to parse the language,

51
00:02:39,920 --> 00:02:43,160
we need a formal definition of a language you want to parse.

52
00:02:43,160 --> 00:02:44,779
So, like writing programs,

53
00:02:44,779 --> 00:02:46,355
it actually has two purposes.

54
00:02:46,355 --> 00:02:49,880
On the one hand, we need to be able to communicate to the computer what

55
00:02:49,880 --> 00:02:53,885
the grammar is and a formal representation's the only way we can do that.

56
00:02:53,885 --> 00:02:56,765
On the other hand, being able to write down the grammar

57
00:02:56,765 --> 00:03:00,005
allows us to communicate with each other about it.

58
00:03:00,005 --> 00:03:03,145
A good grammar is essential for documenting a language.

59
00:03:03,145 --> 00:03:06,980
Grammar is usually assumed that they're operating on tokens, not characters.

60
00:03:06,980 --> 00:03:08,570
So, for the rest of the video,

61
00:03:08,570 --> 00:03:10,534
we'll assume that that's the case.

62
00:03:10,534 --> 00:03:13,120
Now, a grammar has four components.

63
00:03:13,120 --> 00:03:17,540
First, it has a set of symbols that represent individual tokens of words.

64
00:03:17,540 --> 00:03:19,640
These are called terminal symbols.

65
00:03:19,640 --> 00:03:24,725
Second, it has a set of symbols that represent components of trees.

66
00:03:24,725 --> 00:03:26,730
These are called non-terminal symbols.

67
00:03:26,730 --> 00:03:30,560
The easy way to remember the difference is that when you have a terminal symbol,

68
00:03:30,560 --> 00:03:33,425
there are no more work to be done to subdivide it.

69
00:03:33,425 --> 00:03:37,850
The trees are like molecules and terminal symbols are like the atoms.

70
00:03:37,850 --> 00:03:41,560
Now, these symbols are combined to a set of productions.

71
00:03:41,560 --> 00:03:44,240
So, a production is a map from a non-terminal symbol

72
00:03:44,240 --> 00:03:47,419
to a string of terminal and non-terminal symbols.

73
00:03:47,419 --> 00:03:51,230
Now, finally, we pick one special non-terminal symbol to be

74
00:03:51,230 --> 00:03:53,570
the start symbol and this represents the root of

75
00:03:53,570 --> 00:03:56,260
the tree we will get when we parse the program.

76
00:03:56,260 --> 00:03:59,160
Now, let's look at symbols a bit more closely.

77
00:03:59,160 --> 00:04:01,450
As I mentioned in the last slide,

78
00:04:01,450 --> 00:04:05,630
a terminal symbol represents something that is atomic such as nouns,

79
00:04:05,630 --> 00:04:07,345
verbs, integers, et cetera.

80
00:04:07,345 --> 00:04:11,330
It's a lexer's job to put these words together from the individual characters.

81
00:04:11,330 --> 00:04:13,820
The non-terminals represent parts of

82
00:04:13,820 --> 00:04:16,595
the sentence that could be broken into smaller parts.

83
00:04:16,595 --> 00:04:21,155
In English, you might use terms such as prepositional phrase or a dependent clause.

84
00:04:21,155 --> 00:04:23,810
Each of these could contain multiple words.

85
00:04:23,810 --> 00:04:28,100
Here are a few simple examples describing what sentences look like in English,

86
00:04:28,100 --> 00:04:30,835
well, at least, a simplified version of English.

87
00:04:30,835 --> 00:04:33,800
Now, think about it, which of these terms would be

88
00:04:33,800 --> 00:04:38,910
terminal symbols in the grammar and which would be non-terminal symbols?

89
00:04:38,910 --> 00:04:41,775
So, here are the non-terminal symbols;

90
00:04:41,775 --> 00:04:45,310
sentence, noun phrase, and prepositional phrase.

91
00:04:45,310 --> 00:04:47,750
You can tell they're non-terminals quickly because there's

92
00:04:47,750 --> 00:04:51,245
a description of how to assemble them from the component parts.

93
00:04:51,245 --> 00:04:53,630
The remaining words; verb, determinant,

94
00:04:53,630 --> 00:04:56,180
noun, and preposition are all terminal symbols.

95
00:04:56,180 --> 00:05:00,325
Here's one notation we might use to specify a grammar.

96
00:05:00,325 --> 00:05:03,470
In this convention, we use a capital letter to represent

97
00:05:03,470 --> 00:05:07,339
non-terminal symbols and lowercase letters to represent terminals.

98
00:05:07,339 --> 00:05:09,365
So, we have three lines in this grammar.

99
00:05:09,365 --> 00:05:11,470
Each of them is called a production.

100
00:05:11,470 --> 00:05:13,795
So, a production tells us how to build a symbol.

101
00:05:13,795 --> 00:05:16,190
One property of writing a grammar this way.

102
00:05:16,190 --> 00:05:18,680
The rules we have written down say that

103
00:05:18,680 --> 00:05:21,230
these non-terminal symbols can be produced

104
00:05:21,230 --> 00:05:24,340
using the corresponding other symbols on the right-hand side.

105
00:05:24,340 --> 00:05:28,400
There are no other rules or indications about when the production is valid.

106
00:05:28,400 --> 00:05:31,360
The productions are assumed to be valid all the time.

107
00:05:31,360 --> 00:05:34,130
So, this kind of grammar is called a context-free grammar,

108
00:05:34,130 --> 00:05:36,230
and it's the most common grammar by far used in

109
00:05:36,230 --> 00:05:39,830
programming languages since it's easy to write parsers for them.

110
00:05:39,830 --> 00:05:41,780
There are some programming languages that have

111
00:05:41,780 --> 00:05:44,665
context-sensitive grammars but they're pretty rare.

112
00:05:44,665 --> 00:05:48,770
Here is a parse tree that results from using our grammar on the sentence,

113
00:05:48,770 --> 00:05:50,810
"The dog runs under the chair."

114
00:05:50,810 --> 00:05:54,860
The S was the start symbol so it's at the root of the tree.

115
00:05:54,860 --> 00:05:59,035
Here's another example we might see in the context of a programming language.

116
00:05:59,035 --> 00:06:03,544
Here, we have a symbol E that represents expressions and we have four kinds;

117
00:06:03,544 --> 00:06:06,245
plus, variables, greater than, and if.

118
00:06:06,245 --> 00:06:07,655
If you have an expression,

119
00:06:07,655 --> 00:06:10,430
if x greater than y then a plus b else y,

120
00:06:10,430 --> 00:06:14,290
we will get a tree that looks like this one.

121
00:06:14,290 --> 00:06:16,820
So, now that you've seen what a grammar looks like,

122
00:06:16,820 --> 00:06:18,590
let's talk about how you can identify

123
00:06:18,590 --> 00:06:21,590
certain properties that a grammar has by inspecting it.

124
00:06:21,590 --> 00:06:24,800
Four properties we're going to focus on here are these.

125
00:06:24,800 --> 00:06:27,530
You may want to have something called an epsilon

126
00:06:27,530 --> 00:06:31,385
production where the tree can be represented by empty string.

127
00:06:31,385 --> 00:06:36,560
We have grammars that are right linear where all the productions have a restricted form.

128
00:06:36,560 --> 00:06:39,950
We have grammars with recursive productions and sometimes,

129
00:06:39,950 --> 00:06:42,535
that recursion occurs on the leftmost part.

130
00:06:42,535 --> 00:06:44,990
Finally, we have ambiguous grammars that can

131
00:06:44,990 --> 00:06:47,870
produce more than one tree for a given input.

132
00:06:47,870 --> 00:06:50,545
So, let's look at these in turn.

133
00:06:50,545 --> 00:06:53,960
An epsilon production specifies that a symbol can become

134
00:06:53,960 --> 00:06:58,279
nothing or another way of saying this is that a symbol can be considered optional.

135
00:06:58,279 --> 00:07:01,195
To do this, we use the Greek letter Epsilon.

136
00:07:01,195 --> 00:07:04,250
In our example, all grammar for English sentences,

137
00:07:04,250 --> 00:07:05,930
we can use this to add adjectives.

138
00:07:05,930 --> 00:07:08,690
So, in English, you can stack adjectives in front of a noun to

139
00:07:08,690 --> 00:07:12,010
modify it and you can put as many or as few as you want.

140
00:07:12,010 --> 00:07:13,650
To express this with the grammar,

141
00:07:13,650 --> 00:07:18,230
we say that the A tree can be an adjective followed by another A tree or else,

142
00:07:18,230 --> 00:07:19,685
it could just be an epsilon.

143
00:07:19,685 --> 00:07:23,740
It's like saying that the base case is that there are no adjectives at all.

144
00:07:23,740 --> 00:07:27,650
Sometimes, a grammar has a form that every production maps

145
00:07:27,650 --> 00:07:31,715
a non-terminal symbol to either a terminal followed by another non-terminal,

146
00:07:31,715 --> 00:07:33,710
or just a terminal symbol.

147
00:07:33,710 --> 00:07:38,225
These grammars correspond to a class of languages called the regular languages.

148
00:07:38,225 --> 00:07:43,220
They are important because this is a kind of grammar we usually use to specify lexers.

149
00:07:43,220 --> 00:07:47,225
You may have heard of or used regular expressions by now.

150
00:07:47,225 --> 00:07:49,425
This is the kind of grammar that describes them.

151
00:07:49,425 --> 00:07:51,240
Unlike other examples we use,

152
00:07:51,240 --> 00:07:54,640
this kind of grammar works at the character level not just the word level.

153
00:07:54,640 --> 00:07:58,030
We're going to have a separate video to describe these.

154
00:07:58,030 --> 00:08:04,040
If a production has an instance of itself on the right-hand side, it's called recursive.

155
00:08:04,040 --> 00:08:06,890
It turns out that some parsers have trouble if

156
00:08:06,890 --> 00:08:09,595
the recursion occurs in the leftmost position.

157
00:08:09,595 --> 00:08:13,250
Now, here's a few examples of recursive productions.

158
00:08:13,250 --> 00:08:16,010
The if expression has three recursions because an if

159
00:08:16,010 --> 00:08:18,995
expression itself is made up of three sub-expression.

160
00:08:18,995 --> 00:08:21,335
It's not left recursive however.

161
00:08:21,335 --> 00:08:26,329
The next example, E goes to E plus F is left recursive.

162
00:08:26,329 --> 00:08:29,840
Usually, the left recursion will be explicit but it's

163
00:08:29,840 --> 00:08:33,710
possible to have a kind of mutual left recursion like in this third example.

164
00:08:33,710 --> 00:08:35,900
In the context of programming languages though,

165
00:08:35,900 --> 00:08:37,705
this is pretty rare.

166
00:08:37,705 --> 00:08:42,410
It is very important to be able to identify when a grammar is ambiguous.

167
00:08:42,410 --> 00:08:44,750
Some kinds of parsers get stuck if you give them

168
00:08:44,750 --> 00:08:46,760
an ambiguous grammar and others simply

169
00:08:46,760 --> 00:08:49,405
pick one of the possible trees and discard the others.

170
00:08:49,405 --> 00:08:52,130
If that happens, the parser may choose the wrong tree.

171
00:08:52,130 --> 00:08:54,650
You'll learn a formal way of detecting ambiguities,

172
00:08:54,650 --> 00:08:56,540
but there are two patterns of ambiguity that

173
00:08:56,540 --> 00:08:58,790
show up often enough that they're worth learning.

174
00:08:58,790 --> 00:09:01,400
If you see either of these patterns in a grammar,

175
00:09:01,400 --> 00:09:04,435
then you know the grammar is ambiguous right away.

176
00:09:04,435 --> 00:09:07,620
The first is known as the dangling else problem.

177
00:09:07,620 --> 00:09:11,465
In some languages, if statements are allowed to omit the else branch.

178
00:09:11,465 --> 00:09:14,450
This can cause trouble if you have nested if statements.

179
00:09:14,450 --> 00:09:18,200
So, if there's an inner if statement in the then clause of

180
00:09:18,200 --> 00:09:20,800
an outer if statement and you see an else and

181
00:09:20,800 --> 00:09:24,130
you don't know which if statement the else belongs to.

182
00:09:24,130 --> 00:09:29,075
The other form that commonly causes ambiguity is what I call double-ended recursion.

183
00:09:29,075 --> 00:09:33,930
It shows up a lot when people try to make grammars have represent arithmetic expressions.

184
00:09:33,930 --> 00:09:35,985
To fix the dangling else problem,

185
00:09:35,985 --> 00:09:38,960
most languages provide an explicit keyword that

186
00:09:38,960 --> 00:09:42,775
represents the end of an if statement like if I or and if.

187
00:09:42,775 --> 00:09:46,340
For double-ended recursion, the problem is that the grammar does not

188
00:09:46,340 --> 00:09:50,420
specify the precedences are associations of the operations.

189
00:09:50,420 --> 00:09:55,040
To fix this, some tools allow you to specify the precedence levels explicitly.

190
00:09:55,040 --> 00:09:57,710
You can just tell the tool that plus has lower precedence at

191
00:09:57,710 --> 00:10:01,250
times and that you want plus to associate to the right for instance.

192
00:10:01,250 --> 00:10:05,065
But you can also encode this information directly into the grammar,

193
00:10:05,065 --> 00:10:06,630
and here's how you do it.

194
00:10:06,630 --> 00:10:09,320
You create separate non-terminal symbols to

195
00:10:09,320 --> 00:10:12,260
represent each level of precedence in the grammar.

196
00:10:12,260 --> 00:10:14,570
The lower precedences come first,

197
00:10:14,570 --> 00:10:17,170
and the higher precedence levels come later.

198
00:10:17,170 --> 00:10:19,730
The way to remember this is that the lower levels of

199
00:10:19,730 --> 00:10:22,085
the tree bind more tightly than the upper levels.

200
00:10:22,085 --> 00:10:25,445
Therefore, the lower levels represent higher precedence.

201
00:10:25,445 --> 00:10:29,725
The other thing you have to do is get rid of the double-ended recursion.

202
00:10:29,725 --> 00:10:32,060
The trick is that left recursion represents

203
00:10:32,060 --> 00:10:36,350
left associativity and right recursion represents right associativity.

204
00:10:36,350 --> 00:10:39,560
You just have to pick which way you want the associativity to go.

205
00:10:39,560 --> 00:10:41,150
In the example here,

206
00:10:41,150 --> 00:10:43,700
plus expressions are represented by E,

207
00:10:43,700 --> 00:10:45,815
and they are right associative.

208
00:10:45,815 --> 00:10:49,435
F represents factors which are also right associative,

209
00:10:49,435 --> 00:10:53,630
and T represents atomic terms like integers or parenthesized expressions.

210
00:10:53,630 --> 00:10:55,100
In the example here,

211
00:10:55,100 --> 00:10:59,090
plus expressions are represented by E and are right associative.

212
00:10:59,090 --> 00:11:02,420
F represents factors which are also right associative,

213
00:11:02,420 --> 00:11:07,265
and T represents atomic terms like integers or parenthesized expressions.

214
00:11:07,265 --> 00:11:10,060
So, that's it for this part of the introduction.

215
00:11:10,060 --> 00:11:12,200
In the next videos, we'll talk about how

216
00:11:12,200 --> 00:11:14,540
to go about using the grammar to parse something.

217
00:11:14,540 --> 00:11:17,630
It's a big job, so they'll need to be multiple steps.

218
00:11:17,630 --> 00:11:20,210
The first thing we do for many parsers is to

219
00:11:20,210 --> 00:11:23,850
determine the first and follow sets of a grammar.